{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6177ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c1b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file01</td>\n",
       "      <td>[జమ్మూవిల్లే, భారీ వర్షపాతం ద్వారా, చాలా, స్థా...</td>\n",
       "      <td>[B-PLACE-ARG, B-REASON-ARG, O, O, B-NATURAL_EV...</td>\n",
       "      <td>{'NATURAL_EVENT.LAND_SLIDE': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file02</td>\n",
       "      <td>[భూమధ్యరేఖ, బస్సు, ఓవర్‌షాడో, ప్రమాదం:, 11 మంద...</td>\n",
       "      <td>[B-PLACE-ARG, B-MAN_MADE_EVENT.TRANSPORT_HAZAR...</td>\n",
       "      <td>{'MAN_MADE_EVENT.TRANSPORT_HAZARDS': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file03</td>\n",
       "      <td>[ఇరాన్లో, శక్తి, కుడి, భూకంపం:, 2, పాత్ర, త్యా...</td>\n",
       "      <td>[B-PLACE-ARG, B-INTENSITY-ARG, I-INTENSITY-ARG...</td>\n",
       "      <td>{'NATURAL_EVENT.EARTHQUAKE': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file04</td>\n",
       "      <td>[10, చనిపోతారు, ఇన్, ఈజిప్ట్, చర్చి, దాడి., పద...</td>\n",
       "      <td>[B-CASUALTIES-ARG, I-CASUALTIES-ARG, O, B-PLAC...</td>\n",
       "      <td>{'MAN_MADE_EVENT.TERRORIST_ATTACK': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file05</td>\n",
       "      <td>[50, చనిపోయిన, ఇన్, ఆత్మహత్య, బాంబు, దాడి, వద్...</td>\n",
       "      <td>[B-CASUALTIES-ARG, I-CASUALTIES-ARG, O, B-MAN_...</td>\n",
       "      <td>{'MAN_MADE_EVENT.SUICIDE_ATTACK': 7}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                                             tokens  \\\n",
       "0  file01  [జమ్మూవిల్లే, భారీ వర్షపాతం ద్వారా, చాలా, స్థా...   \n",
       "1  file02  [భూమధ్యరేఖ, బస్సు, ఓవర్‌షాడో, ప్రమాదం:, 11 మంద...   \n",
       "2  file03  [ఇరాన్లో, శక్తి, కుడి, భూకంపం:, 2, పాత్ర, త్యా...   \n",
       "3  file04  [10, చనిపోతారు, ఇన్, ఈజిప్ట్, చర్చి, దాడి., పద...   \n",
       "4  file05  [50, చనిపోయిన, ఇన్, ఆత్మహత్య, బాంబు, దాడి, వద్...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [B-PLACE-ARG, B-REASON-ARG, O, O, B-NATURAL_EV...   \n",
       "1  [B-PLACE-ARG, B-MAN_MADE_EVENT.TRANSPORT_HAZAR...   \n",
       "2  [B-PLACE-ARG, B-INTENSITY-ARG, I-INTENSITY-ARG...   \n",
       "3  [B-CASUALTIES-ARG, I-CASUALTIES-ARG, O, B-PLAC...   \n",
       "4  [B-CASUALTIES-ARG, I-CASUALTIES-ARG, O, B-MAN_...   \n",
       "\n",
       "                                    labels  \n",
       "0          {'NATURAL_EVENT.LAND_SLIDE': 5}  \n",
       "1  {'MAN_MADE_EVENT.TRANSPORT_HAZARDS': 8}  \n",
       "2          {'NATURAL_EVENT.EARTHQUAKE': 7}  \n",
       "3   {'MAN_MADE_EVENT.TERRORIST_ATTACK': 7}  \n",
       "4     {'MAN_MADE_EVENT.SUICIDE_ATTACK': 7}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_json(\"./data/processed/te/train.json\", orient=\"records\", lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c9105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:33:32,746] A new study created in memory with name: no-name-fcec8e9e-a99c-4b09-bcb0-9360d834f0f5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1: emb=105, hid=170, drop=0.41, lr=0.00089, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.2848, Loss: 4.4565 - Val Acc: 0.4734\n",
      "  Epoch 2/30 - Train Acc: 0.5479, Loss: 4.0616 - Val Acc: 0.6283\n",
      "  Epoch 3/30 - Train Acc: 0.6444, Loss: 3.6265 - Val Acc: 0.6360\n",
      "  Epoch 4/30 - Train Acc: 0.6716, Loss: 3.1770 - Val Acc: 0.6659\n",
      "  Epoch 5/30 - Train Acc: 0.6854, Loss: 2.7492 - Val Acc: 0.6706\n",
      "  Epoch 6/30 - Train Acc: 0.6926, Loss: 2.3784 - Val Acc: 0.6749\n",
      "  Epoch 7/30 - Train Acc: 0.6950, Loss: 2.0801 - Val Acc: 0.6774\n",
      "  Epoch 8/30 - Train Acc: 0.6957, Loss: 1.8504 - Val Acc: 0.6780\n",
      "  Epoch 9/30 - Train Acc: 0.6959, Loss: 1.6924 - Val Acc: 0.6780\n",
      "  Epoch 10/30 - Train Acc: 0.6960, Loss: 1.5779 - Val Acc: 0.6778\n",
      "  Epoch 11/30 - Train Acc: 0.6960, Loss: 1.5014 - Val Acc: 0.6781\n",
      "  Epoch 12/30 - Train Acc: 0.6961, Loss: 1.4432 - Val Acc: 0.6780\n",
      "  Epoch 13/30 - Train Acc: 0.6961, Loss: 1.4023 - Val Acc: 0.6778\n",
      "  Epoch 14/30 - Train Acc: 0.6961, Loss: 1.3699 - Val Acc: 0.6781\n",
      "  Epoch 15/30 - Train Acc: 0.6961, Loss: 1.3390 - Val Acc: 0.6778\n",
      "  Epoch 16/30 - Train Acc: 0.6961, Loss: 1.3175 - Val Acc: 0.6767\n",
      "  Epoch 17/30 - Train Acc: 0.6960, Loss: 1.2976 - Val Acc: 0.6779\n",
      "  Epoch 18/30 - Train Acc: 0.6961, Loss: 1.2734 - Val Acc: 0.6765\n",
      "  Epoch 19/30 - Train Acc: 0.6963, Loss: 1.2606 - Val Acc: 0.6772\n",
      "  Epoch 20/30 - Train Acc: 0.6964, Loss: 1.2370 - Val Acc: 0.6773\n",
      "  Epoch 21/30 - Train Acc: 0.6967, Loss: 1.2209 - Val Acc: 0.6773\n",
      "  Epoch 22/30 - Train Acc: 0.6972, Loss: 1.2046 - Val Acc: 0.6771\n",
      "  Epoch 23/30 - Train Acc: 0.6975, Loss: 1.1885 - Val Acc: 0.6767\n",
      "  Epoch 24/30 - Train Acc: 0.6977, Loss: 1.1741 - Val Acc: 0.6751\n",
      "  Epoch 25/30 - Train Acc: 0.6982, Loss: 1.1596 - Val Acc: 0.6755\n",
      "  Epoch 26/30 - Train Acc: 0.6987, Loss: 1.1439 - Val Acc: 0.6759\n",
      "  Epoch 27/30 - Train Acc: 0.6991, Loss: 1.1267 - Val Acc: 0.6762\n",
      "  Epoch 28/30 - Train Acc: 0.6995, Loss: 1.1194 - Val Acc: 0.6740\n",
      "  Epoch 29/30 - Train Acc: 0.7003, Loss: 1.1012 - Val Acc: 0.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:35:07,016] Trial 0 finished with value: 0.6781277807439046 and parameters: {'embedding_dim': 105, 'hidden_dim': 170, 'dropout': 0.4106635325123241, 'lr': 0.00089426356785894, 'batch_size': 32}. Best is trial 0 with value: 0.6781277807439046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.7005, Loss: 1.0873 - Val Acc: 0.6744\n",
      "Trial 1 Done: Val Accuracy = 0.6781, Final Loss = 1.0873\n",
      "\n",
      "Trial 2: emb=93, hid=187, drop=0.46, lr=0.00106, batch=16\n",
      "  Epoch 1/30 - Train Acc: 0.6824, Loss: 4.1346 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 3.1026 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 2.1981 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.7016 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.5064 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.4237 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 1.3767 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.3439 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 1.3122 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 1.2885 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 1.2658 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 1.2403 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 1.2118 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 1.1885 - Val Acc: 0.6783\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 1.1635 - Val Acc: 0.6779\n",
      "  Epoch 16/30 - Train Acc: 0.6957, Loss: 1.1372 - Val Acc: 0.6759\n",
      "  Epoch 17/30 - Train Acc: 0.6955, Loss: 1.1140 - Val Acc: 0.6740\n",
      "  Epoch 18/30 - Train Acc: 0.6952, Loss: 1.0862 - Val Acc: 0.6705\n",
      "  Epoch 19/30 - Train Acc: 0.6951, Loss: 1.0639 - Val Acc: 0.6693\n",
      "  Epoch 20/30 - Train Acc: 0.6952, Loss: 1.0399 - Val Acc: 0.6656\n",
      "  Epoch 21/30 - Train Acc: 0.6970, Loss: 1.0209 - Val Acc: 0.6598\n",
      "  Epoch 22/30 - Train Acc: 0.7007, Loss: 1.0026 - Val Acc: 0.6700\n",
      "  Epoch 23/30 - Train Acc: 0.7144, Loss: 0.9788 - Val Acc: 0.6671\n",
      "  Epoch 24/30 - Train Acc: 0.7260, Loss: 0.9544 - Val Acc: 0.6675\n",
      "  Epoch 25/30 - Train Acc: 0.7379, Loss: 0.9265 - Val Acc: 0.6743\n",
      "  Epoch 26/30 - Train Acc: 0.7462, Loss: 0.9002 - Val Acc: 0.6737\n",
      "  Epoch 27/30 - Train Acc: 0.7525, Loss: 0.8744 - Val Acc: 0.6772\n",
      "  Epoch 28/30 - Train Acc: 0.7597, Loss: 0.8491 - Val Acc: 0.6745\n",
      "  Epoch 29/30 - Train Acc: 0.7703, Loss: 0.8258 - Val Acc: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:37:05,960] Trial 1 finished with value: 0.6838583377825236 and parameters: {'embedding_dim': 93, 'hidden_dim': 187, 'dropout': 0.46242385404643693, 'lr': 0.0010568415679659353, 'batch_size': 16}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.7843, Loss: 0.8004 - Val Acc: 0.6839\n",
      "Trial 2 Done: Val Accuracy = 0.6839, Final Loss = 0.8004\n",
      "\n",
      "Trial 3: emb=104, hid=205, drop=0.48, lr=0.00075, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.4868, Loss: 4.5297 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 4.3193 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 4.1303 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 3.9331 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 3.7241 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 3.5080 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 3.3021 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 3.0808 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 2.8741 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 2.6805 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 2.4996 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 2.3355 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 2.1896 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 2.0573 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 1.9501 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 1.8510 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 1.7673 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 1.6964 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 1.6378 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 1.5832 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 1.5312 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 1.4919 - Val Acc: 0.6784\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 1.4632 - Val Acc: 0.6783\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 1.4255 - Val Acc: 0.6783\n",
      "  Epoch 25/30 - Train Acc: 0.6961, Loss: 1.4008 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6961, Loss: 1.3793 - Val Acc: 0.6781\n",
      "  Epoch 27/30 - Train Acc: 0.6961, Loss: 1.3535 - Val Acc: 0.6781\n",
      "  Epoch 28/30 - Train Acc: 0.6961, Loss: 1.3368 - Val Acc: 0.6778\n",
      "  Epoch 29/30 - Train Acc: 0.6961, Loss: 1.3189 - Val Acc: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:37:50,122] Trial 2 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 104, 'hidden_dim': 205, 'dropout': 0.4829299933786664, 'lr': 0.0007488276419263299, 'batch_size': 64}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6961, Loss: 1.3015 - Val Acc: 0.6779\n",
      "Trial 3 Done: Val Accuracy = 0.6784, Final Loss = 1.3015\n",
      "\n",
      "Trial 4: emb=126, hid=210, drop=0.41, lr=0.00048, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.6185, Loss: 4.4849 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 4.2198 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 3.9665 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 3.6994 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 3.4261 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 3.1553 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 2.8970 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 2.6579 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 2.4395 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 2.2429 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 2.0808 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 1.9398 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 1.8151 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 1.7167 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 1.6380 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 1.5718 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 1.5193 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 1.4747 - Val Acc: 0.6783\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 1.4431 - Val Acc: 0.6783\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 1.4092 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 1.3845 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 1.3678 - Val Acc: 0.6783\n",
      "  Epoch 23/30 - Train Acc: 0.6961, Loss: 1.3386 - Val Acc: 0.6781\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 1.3189 - Val Acc: 0.6781\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 1.3066 - Val Acc: 0.6777\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 1.2846 - Val Acc: 0.6778\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 1.2739 - Val Acc: 0.6781\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 1.2590 - Val Acc: 0.6774\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 1.2450 - Val Acc: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:38:45,253] Trial 3 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 126, 'hidden_dim': 210, 'dropout': 0.4134055223891382, 'lr': 0.0004787198758857231, 'batch_size': 32}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 1.2331 - Val Acc: 0.6766\n",
      "Trial 4 Done: Val Accuracy = 0.6784, Final Loss = 1.2331\n",
      "\n",
      "Trial 5: emb=85, hid=142, drop=0.25, lr=0.00045, batch=16\n",
      "  Epoch 1/30 - Train Acc: 0.2468, Loss: 4.4585 - Val Acc: 0.4203\n",
      "  Epoch 2/30 - Train Acc: 0.5286, Loss: 4.0907 - Val Acc: 0.5922\n",
      "  Epoch 3/30 - Train Acc: 0.6530, Loss: 3.6908 - Val Acc: 0.6518\n",
      "  Epoch 4/30 - Train Acc: 0.6802, Loss: 3.2788 - Val Acc: 0.6702\n",
      "  Epoch 5/30 - Train Acc: 0.6935, Loss: 2.8807 - Val Acc: 0.6779\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 2.5232 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 2.2242 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.9874 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 1.8011 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 1.6699 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 1.5741 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 1.5085 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 1.4570 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 1.4215 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 1.3916 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6961, Loss: 1.3673 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 1.3452 - Val Acc: 0.6783\n",
      "  Epoch 18/30 - Train Acc: 0.6961, Loss: 1.3265 - Val Acc: 0.6782\n",
      "  Epoch 19/30 - Train Acc: 0.6961, Loss: 1.3071 - Val Acc: 0.6782\n",
      "  Epoch 20/30 - Train Acc: 0.6961, Loss: 1.2883 - Val Acc: 0.6782\n",
      "  Epoch 21/30 - Train Acc: 0.6961, Loss: 1.2721 - Val Acc: 0.6781\n",
      "  Epoch 22/30 - Train Acc: 0.6960, Loss: 1.2568 - Val Acc: 0.6778\n",
      "  Epoch 23/30 - Train Acc: 0.6960, Loss: 1.2441 - Val Acc: 0.6775\n",
      "  Epoch 24/30 - Train Acc: 0.6960, Loss: 1.2282 - Val Acc: 0.6775\n",
      "  Epoch 25/30 - Train Acc: 0.6960, Loss: 1.2132 - Val Acc: 0.6775\n",
      "  Epoch 26/30 - Train Acc: 0.6960, Loss: 1.2047 - Val Acc: 0.6772\n",
      "  Epoch 27/30 - Train Acc: 0.6960, Loss: 1.1881 - Val Acc: 0.6762\n",
      "  Epoch 28/30 - Train Acc: 0.6960, Loss: 1.1735 - Val Acc: 0.6756\n",
      "  Epoch 29/30 - Train Acc: 0.6961, Loss: 1.1631 - Val Acc: 0.6755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:40:04,574] Trial 4 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 85, 'hidden_dim': 142, 'dropout': 0.24654572010311984, 'lr': 0.0004547147374385302, 'batch_size': 16}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 1.1534 - Val Acc: 0.6766\n",
      "Trial 5 Done: Val Accuracy = 0.6784, Final Loss = 1.1534\n",
      "\n",
      "Trial 6: emb=114, hid=191, drop=0.27, lr=0.00066, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.1229, Loss: 4.5866 - Val Acc: 0.2235\n",
      "  Epoch 2/30 - Train Acc: 0.2864, Loss: 4.3974 - Val Acc: 0.3416\n",
      "  Epoch 3/30 - Train Acc: 0.4246, Loss: 4.2357 - Val Acc: 0.4924\n",
      "  Epoch 4/30 - Train Acc: 0.5488, Loss: 4.0642 - Val Acc: 0.6005\n",
      "  Epoch 5/30 - Train Acc: 0.6113, Loss: 3.8838 - Val Acc: 0.6325\n",
      "  Epoch 6/30 - Train Acc: 0.6433, Loss: 3.7023 - Val Acc: 0.6250\n",
      "  Epoch 7/30 - Train Acc: 0.6540, Loss: 3.5121 - Val Acc: 0.6367\n",
      "  Epoch 8/30 - Train Acc: 0.6620, Loss: 3.3288 - Val Acc: 0.6488\n",
      "  Epoch 9/30 - Train Acc: 0.6714, Loss: 3.1457 - Val Acc: 0.6512\n",
      "  Epoch 10/30 - Train Acc: 0.6776, Loss: 2.9638 - Val Acc: 0.6635\n",
      "  Epoch 11/30 - Train Acc: 0.6834, Loss: 2.7951 - Val Acc: 0.6695\n",
      "  Epoch 12/30 - Train Acc: 0.6874, Loss: 2.6311 - Val Acc: 0.6680\n",
      "  Epoch 13/30 - Train Acc: 0.6902, Loss: 2.4769 - Val Acc: 0.6688\n",
      "  Epoch 14/30 - Train Acc: 0.6922, Loss: 2.3384 - Val Acc: 0.6676\n",
      "  Epoch 15/30 - Train Acc: 0.6938, Loss: 2.2156 - Val Acc: 0.6674\n",
      "  Epoch 16/30 - Train Acc: 0.6945, Loss: 2.0997 - Val Acc: 0.6752\n",
      "  Epoch 17/30 - Train Acc: 0.6950, Loss: 1.9928 - Val Acc: 0.6753\n",
      "  Epoch 18/30 - Train Acc: 0.6954, Loss: 1.9021 - Val Acc: 0.6765\n",
      "  Epoch 19/30 - Train Acc: 0.6956, Loss: 1.8311 - Val Acc: 0.6775\n",
      "  Epoch 20/30 - Train Acc: 0.6959, Loss: 1.7594 - Val Acc: 0.6757\n",
      "  Epoch 21/30 - Train Acc: 0.6959, Loss: 1.6978 - Val Acc: 0.6777\n",
      "  Epoch 22/30 - Train Acc: 0.6960, Loss: 1.6374 - Val Acc: 0.6777\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 1.5871 - Val Acc: 0.6772\n",
      "  Epoch 24/30 - Train Acc: 0.6963, Loss: 1.5441 - Val Acc: 0.6779\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 1.5104 - Val Acc: 0.6779\n",
      "  Epoch 26/30 - Train Acc: 0.6963, Loss: 1.4750 - Val Acc: 0.6778\n",
      "  Epoch 27/30 - Train Acc: 0.6963, Loss: 1.4493 - Val Acc: 0.6775\n",
      "  Epoch 28/30 - Train Acc: 0.6964, Loss: 1.4267 - Val Acc: 0.6772\n",
      "  Epoch 29/30 - Train Acc: 0.6964, Loss: 1.4001 - Val Acc: 0.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:41:39,619] Trial 5 finished with value: 0.6781277807439046 and parameters: {'embedding_dim': 114, 'hidden_dim': 191, 'dropout': 0.2732478099757905, 'lr': 0.0006625175180949738, 'batch_size': 64}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6964, Loss: 1.3808 - Val Acc: 0.6778\n",
      "Trial 6 Done: Val Accuracy = 0.6781, Final Loss = 1.3808\n",
      "\n",
      "Trial 7: emb=90, hid=250, drop=0.43, lr=0.00017, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.2119, Loss: 4.5786 - Val Acc: 0.5130\n",
      "  Epoch 2/30 - Train Acc: 0.6710, Loss: 4.4165 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 4.2953 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 4.1946 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 4.0937 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 3.9895 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 3.8840 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 3.7770 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 3.6689 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 3.5612 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 3.4536 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 3.3469 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 3.2398 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 3.1355 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 3.0328 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 2.9319 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 2.8344 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 2.7389 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 2.6520 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 2.5605 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 2.4750 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 2.3977 - Val Acc: 0.6784\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 2.3196 - Val Acc: 0.6784\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 2.2459 - Val Acc: 0.6784\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 2.1763 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 2.1126 - Val Acc: 0.6784\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 2.0540 - Val Acc: 0.6784\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 1.9961 - Val Acc: 0.6784\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 1.9452 - Val Acc: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:42:59,939] Trial 6 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 90, 'hidden_dim': 250, 'dropout': 0.4262985751361407, 'lr': 0.00017437187993963647, 'batch_size': 32}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 1.8939 - Val Acc: 0.6784\n",
      "Trial 7 Done: Val Accuracy = 0.6784, Final Loss = 1.8939\n",
      "\n",
      "Trial 8: emb=101, hid=156, drop=0.27, lr=0.00023, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.5709, Loss: 4.5916 - Val Acc: 0.6781\n",
      "  Epoch 2/30 - Train Acc: 0.6961, Loss: 4.5362 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 4.4768 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 4.4036 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 4.3435 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 4.2900 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 4.2374 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 4.1842 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 4.1298 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 4.0759 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 4.0214 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 3.9664 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 3.9118 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 3.8563 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 3.8009 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 3.7434 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 3.6873 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 3.6294 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 3.5738 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 3.5151 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 3.4600 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 3.4054 - Val Acc: 0.6784\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 3.3477 - Val Acc: 0.6784\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 3.2906 - Val Acc: 0.6784\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 3.2339 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 3.1826 - Val Acc: 0.6784\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 3.1243 - Val Acc: 0.6784\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 3.0689 - Val Acc: 0.6784\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 3.0168 - Val Acc: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:44:13,288] Trial 7 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 101, 'hidden_dim': 156, 'dropout': 0.26650323770560774, 'lr': 0.0002287890430242527, 'batch_size': 64}. Best is trial 1 with value: 0.6838583377825236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 2.9599 - Val Acc: 0.6784\n",
      "Trial 8 Done: Val Accuracy = 0.6784, Final Loss = 2.9599\n",
      "\n",
      "Trial 9: emb=84, hid=156, drop=0.41, lr=0.00608, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.5140, Loss: 4.1646 - Val Acc: 0.6502\n",
      "  Epoch 2/30 - Train Acc: 0.6884, Loss: 2.9218 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.8811 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.4803 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.3764 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.3301 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 1.2890 - Val Acc: 0.6781\n",
      "  Epoch 8/30 - Train Acc: 0.6958, Loss: 1.2569 - Val Acc: 0.6776\n",
      "  Epoch 9/30 - Train Acc: 0.6955, Loss: 1.2205 - Val Acc: 0.6761\n",
      "  Epoch 10/30 - Train Acc: 0.6952, Loss: 1.1838 - Val Acc: 0.6763\n",
      "  Epoch 11/30 - Train Acc: 0.6951, Loss: 1.1491 - Val Acc: 0.6746\n",
      "  Epoch 12/30 - Train Acc: 0.6957, Loss: 1.1174 - Val Acc: 0.6740\n",
      "  Epoch 13/30 - Train Acc: 0.6994, Loss: 1.0762 - Val Acc: 0.6740\n",
      "  Epoch 14/30 - Train Acc: 0.7162, Loss: 1.0388 - Val Acc: 0.6768\n",
      "  Epoch 15/30 - Train Acc: 0.7326, Loss: 0.9988 - Val Acc: 0.6792\n",
      "  Epoch 16/30 - Train Acc: 0.7439, Loss: 0.9551 - Val Acc: 0.6772\n",
      "  Epoch 17/30 - Train Acc: 0.7605, Loss: 0.9082 - Val Acc: 0.6884\n",
      "  Epoch 18/30 - Train Acc: 0.7860, Loss: 0.8496 - Val Acc: 0.6992\n",
      "  Epoch 19/30 - Train Acc: 0.8092, Loss: 0.7860 - Val Acc: 0.7038\n",
      "  Epoch 20/30 - Train Acc: 0.8240, Loss: 0.7380 - Val Acc: 0.7039\n",
      "  Epoch 21/30 - Train Acc: 0.8361, Loss: 0.6918 - Val Acc: 0.7032\n",
      "  Epoch 22/30 - Train Acc: 0.8453, Loss: 0.6555 - Val Acc: 0.7100\n",
      "  Epoch 23/30 - Train Acc: 0.8533, Loss: 0.6219 - Val Acc: 0.7083\n",
      "  Epoch 24/30 - Train Acc: 0.8597, Loss: 0.5940 - Val Acc: 0.7067\n",
      "  Epoch 25/30 - Train Acc: 0.8656, Loss: 0.5687 - Val Acc: 0.7105\n",
      "  Epoch 26/30 - Train Acc: 0.8711, Loss: 0.5494 - Val Acc: 0.7124\n",
      "  Epoch 27/30 - Train Acc: 0.8762, Loss: 0.5318 - Val Acc: 0.7099\n",
      "  Epoch 28/30 - Train Acc: 0.8812, Loss: 0.5131 - Val Acc: 0.7087\n",
      "  Epoch 29/30 - Train Acc: 0.8859, Loss: 0.4971 - Val Acc: 0.7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:45:27,263] Trial 8 finished with value: 0.7123687488877024 and parameters: {'embedding_dim': 84, 'hidden_dim': 156, 'dropout': 0.41188938009939935, 'lr': 0.0060797505820611025, 'batch_size': 64}. Best is trial 8 with value: 0.7123687488877024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.8889, Loss: 0.4811 - Val Acc: 0.7090\n",
      "Trial 9 Done: Val Accuracy = 0.7124, Final Loss = 0.4811\n",
      "\n",
      "Trial 10: emb=121, hid=202, drop=0.24, lr=0.00855, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.5729, Loss: 3.8627 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 2.0948 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.4452 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.3440 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.2861 - Val Acc: 0.6783\n",
      "  Epoch 6/30 - Train Acc: 0.6959, Loss: 1.2309 - Val Acc: 0.6775\n",
      "  Epoch 7/30 - Train Acc: 0.6956, Loss: 1.1718 - Val Acc: 0.6763\n",
      "  Epoch 8/30 - Train Acc: 0.7155, Loss: 1.0886 - Val Acc: 0.6825\n",
      "  Epoch 9/30 - Train Acc: 0.7449, Loss: 0.9925 - Val Acc: 0.6987\n",
      "  Epoch 10/30 - Train Acc: 0.7829, Loss: 0.8833 - Val Acc: 0.7084\n",
      "  Epoch 11/30 - Train Acc: 0.8110, Loss: 0.7845 - Val Acc: 0.7135\n",
      "  Epoch 12/30 - Train Acc: 0.8335, Loss: 0.6974 - Val Acc: 0.7191\n",
      "  Epoch 13/30 - Train Acc: 0.8527, Loss: 0.6248 - Val Acc: 0.7248\n",
      "  Epoch 14/30 - Train Acc: 0.8667, Loss: 0.5697 - Val Acc: 0.7281\n",
      "  Epoch 15/30 - Train Acc: 0.8779, Loss: 0.5183 - Val Acc: 0.7268\n",
      "  Epoch 16/30 - Train Acc: 0.8885, Loss: 0.4738 - Val Acc: 0.7305\n",
      "  Epoch 17/30 - Train Acc: 0.8958, Loss: 0.4383 - Val Acc: 0.7308\n",
      "  Epoch 18/30 - Train Acc: 0.9036, Loss: 0.4051 - Val Acc: 0.7302\n",
      "  Epoch 19/30 - Train Acc: 0.9123, Loss: 0.3678 - Val Acc: 0.7300\n",
      "  Epoch 20/30 - Train Acc: 0.9170, Loss: 0.3448 - Val Acc: 0.7286\n",
      "  Epoch 21/30 - Train Acc: 0.9227, Loss: 0.3216 - Val Acc: 0.7327\n",
      "  Epoch 22/30 - Train Acc: 0.9279, Loss: 0.2989 - Val Acc: 0.7353\n",
      "  Epoch 23/30 - Train Acc: 0.9322, Loss: 0.2805 - Val Acc: 0.7344\n",
      "  Epoch 24/30 - Train Acc: 0.9375, Loss: 0.2621 - Val Acc: 0.7343\n",
      "  Epoch 25/30 - Train Acc: 0.9425, Loss: 0.2415 - Val Acc: 0.7359\n",
      "  Epoch 26/30 - Train Acc: 0.9465, Loss: 0.2210 - Val Acc: 0.7387\n",
      "  Epoch 27/30 - Train Acc: 0.9504, Loss: 0.2041 - Val Acc: 0.7391\n",
      "  Epoch 28/30 - Train Acc: 0.9548, Loss: 0.1866 - Val Acc: 0.7394\n",
      "  Epoch 29/30 - Train Acc: 0.9580, Loss: 0.1728 - Val Acc: 0.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:46:28,983] Trial 9 finished with value: 0.7393842320697633 and parameters: {'embedding_dim': 121, 'hidden_dim': 202, 'dropout': 0.23970141173967827, 'lr': 0.00855370882946973, 'batch_size': 64}. Best is trial 9 with value: 0.7393842320697633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.9607, Loss: 0.1584 - Val Acc: 0.7390\n",
      "Trial 10 Done: Val Accuracy = 0.7394, Final Loss = 0.1584\n",
      "\n",
      "Trial 11: emb=85, hid=160, drop=0.22, lr=0.00015, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.0330, Loss: 4.6613 - Val Acc: 0.0771\n",
      "  Epoch 2/30 - Train Acc: 0.0938, Loss: 4.6023 - Val Acc: 0.1183\n",
      "  Epoch 3/30 - Train Acc: 0.1409, Loss: 4.5499 - Val Acc: 0.1906\n",
      "  Epoch 4/30 - Train Acc: 0.2459, Loss: 4.5017 - Val Acc: 0.2894\n",
      "  Epoch 5/30 - Train Acc: 0.3393, Loss: 4.4609 - Val Acc: 0.3735\n",
      "  Epoch 6/30 - Train Acc: 0.4379, Loss: 4.4261 - Val Acc: 0.4612\n",
      "  Epoch 7/30 - Train Acc: 0.5542, Loss: 4.3937 - Val Acc: 0.6212\n",
      "  Epoch 8/30 - Train Acc: 0.6845, Loss: 4.3624 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 4.3297 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 4.2973 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 4.2645 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 4.2316 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 4.1981 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 4.1647 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 4.1306 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 4.0960 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 4.0611 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 4.0262 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 3.9919 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 3.9576 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 3.9226 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 3.8869 - Val Acc: 0.6784\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 3.8524 - Val Acc: 0.6784\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 3.8174 - Val Acc: 0.6784\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 3.7815 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 3.7458 - Val Acc: 0.6784\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 3.7098 - Val Acc: 0.6784\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 3.6739 - Val Acc: 0.6784\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 3.6376 - Val Acc: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:47:42,974] Trial 10 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 85, 'hidden_dim': 160, 'dropout': 0.21553270760196677, 'lr': 0.00014519770367721425, 'batch_size': 64}. Best is trial 9 with value: 0.7393842320697633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 3.6011 - Val Acc: 0.6784\n",
      "Trial 11 Done: Val Accuracy = 0.6784, Final Loss = 3.6011\n",
      "\n",
      "Trial 12: emb=99, hid=212, drop=0.50, lr=0.00474, batch=16\n",
      "  Epoch 1/30 - Train Acc: 0.6346, Loss: 2.7668 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 1.4336 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.3603 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.2737 - Val Acc: 0.6782\n",
      "  Epoch 5/30 - Train Acc: 0.7071, Loss: 1.1744 - Val Acc: 0.6932\n",
      "  Epoch 6/30 - Train Acc: 0.7404, Loss: 1.0493 - Val Acc: 0.7015\n",
      "  Epoch 7/30 - Train Acc: 0.7750, Loss: 0.9114 - Val Acc: 0.7180\n",
      "  Epoch 8/30 - Train Acc: 0.8072, Loss: 0.7945 - Val Acc: 0.7257\n",
      "  Epoch 9/30 - Train Acc: 0.8291, Loss: 0.7052 - Val Acc: 0.7218\n",
      "  Epoch 10/30 - Train Acc: 0.8490, Loss: 0.6185 - Val Acc: 0.7342\n",
      "  Epoch 11/30 - Train Acc: 0.8647, Loss: 0.5516 - Val Acc: 0.7379\n",
      "  Epoch 12/30 - Train Acc: 0.8776, Loss: 0.4940 - Val Acc: 0.7368\n",
      "  Epoch 13/30 - Train Acc: 0.8900, Loss: 0.4426 - Val Acc: 0.7405\n",
      "  Epoch 14/30 - Train Acc: 0.9001, Loss: 0.3977 - Val Acc: 0.7356\n",
      "  Epoch 15/30 - Train Acc: 0.9094, Loss: 0.3583 - Val Acc: 0.7395\n",
      "  Epoch 16/30 - Train Acc: 0.9182, Loss: 0.3206 - Val Acc: 0.7402\n",
      "  Epoch 17/30 - Train Acc: 0.9250, Loss: 0.2924 - Val Acc: 0.7395\n",
      "  Epoch 18/30 - Train Acc: 0.9324, Loss: 0.2607 - Val Acc: 0.7430\n",
      "  Epoch 19/30 - Train Acc: 0.9376, Loss: 0.2380 - Val Acc: 0.7415\n",
      "  Epoch 20/30 - Train Acc: 0.9426, Loss: 0.2170 - Val Acc: 0.7426\n",
      "  Epoch 21/30 - Train Acc: 0.9471, Loss: 0.1988 - Val Acc: 0.7442\n",
      "  Epoch 22/30 - Train Acc: 0.9518, Loss: 0.1792 - Val Acc: 0.7447\n",
      "  Epoch 23/30 - Train Acc: 0.9553, Loss: 0.1652 - Val Acc: 0.7464\n",
      "  Epoch 24/30 - Train Acc: 0.9581, Loss: 0.1531 - Val Acc: 0.7492\n",
      "  Epoch 25/30 - Train Acc: 0.9609, Loss: 0.1426 - Val Acc: 0.7459\n",
      "  Epoch 26/30 - Train Acc: 0.9639, Loss: 0.1307 - Val Acc: 0.7494\n",
      "  Epoch 27/30 - Train Acc: 0.9672, Loss: 0.1180 - Val Acc: 0.7458\n",
      "  Epoch 28/30 - Train Acc: 0.9688, Loss: 0.1110 - Val Acc: 0.7427\n",
      "  Epoch 29/30 - Train Acc: 0.9707, Loss: 0.1043 - Val Acc: 0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:49:51,684] Trial 11 finished with value: 0.7493860117458623 and parameters: {'embedding_dim': 99, 'hidden_dim': 212, 'dropout': 0.49925576681424444, 'lr': 0.004737349647790637, 'batch_size': 16}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.9729, Loss: 0.0965 - Val Acc: 0.7468\n",
      "Trial 12 Done: Val Accuracy = 0.7494, Final Loss = 0.0965\n",
      "\n",
      "Trial 13: emb=83, hid=160, drop=0.21, lr=0.00397, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.4917, Loss: 3.9442 - Val Acc: 0.6695\n",
      "  Epoch 2/30 - Train Acc: 0.6943, Loss: 2.3359 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.5515 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.3934 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6963, Loss: 1.3288 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.2909 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6958, Loss: 1.2329 - Val Acc: 0.6770\n",
      "  Epoch 8/30 - Train Acc: 0.6958, Loss: 1.1702 - Val Acc: 0.6777\n",
      "  Epoch 9/30 - Train Acc: 0.7153, Loss: 1.1010 - Val Acc: 0.6853\n",
      "  Epoch 10/30 - Train Acc: 0.7363, Loss: 1.0257 - Val Acc: 0.6944\n",
      "  Epoch 11/30 - Train Acc: 0.7610, Loss: 0.9485 - Val Acc: 0.7004\n",
      "  Epoch 12/30 - Train Acc: 0.7886, Loss: 0.8627 - Val Acc: 0.7049\n",
      "  Epoch 13/30 - Train Acc: 0.8119, Loss: 0.7843 - Val Acc: 0.7073\n",
      "  Epoch 14/30 - Train Acc: 0.8284, Loss: 0.7187 - Val Acc: 0.7096\n",
      "  Epoch 15/30 - Train Acc: 0.8413, Loss: 0.6638 - Val Acc: 0.7124\n",
      "  Epoch 16/30 - Train Acc: 0.8543, Loss: 0.6109 - Val Acc: 0.7091\n",
      "  Epoch 17/30 - Train Acc: 0.8653, Loss: 0.5686 - Val Acc: 0.7125\n",
      "  Epoch 18/30 - Train Acc: 0.8752, Loss: 0.5268 - Val Acc: 0.7099\n",
      "  Epoch 19/30 - Train Acc: 0.8844, Loss: 0.4950 - Val Acc: 0.7170\n",
      "  Epoch 20/30 - Train Acc: 0.8930, Loss: 0.4642 - Val Acc: 0.7220\n",
      "  Epoch 21/30 - Train Acc: 0.9000, Loss: 0.4368 - Val Acc: 0.7183\n",
      "  Epoch 22/30 - Train Acc: 0.9048, Loss: 0.4147 - Val Acc: 0.7166\n",
      "  Epoch 23/30 - Train Acc: 0.9087, Loss: 0.3954 - Val Acc: 0.7201\n",
      "  Epoch 24/30 - Train Acc: 0.9123, Loss: 0.3785 - Val Acc: 0.7189\n",
      "  Epoch 25/30 - Train Acc: 0.9147, Loss: 0.3656 - Val Acc: 0.7214\n",
      "  Epoch 26/30 - Train Acc: 0.9174, Loss: 0.3528 - Val Acc: 0.7166\n",
      "  Epoch 27/30 - Train Acc: 0.9223, Loss: 0.3341 - Val Acc: 0.7196\n",
      "  Epoch 28/30 - Train Acc: 0.9264, Loss: 0.3171 - Val Acc: 0.7162\n",
      "  Epoch 29/30 - Train Acc: 0.9301, Loss: 0.3034 - Val Acc: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:51:23,030] Trial 12 finished with value: 0.7219789998220324 and parameters: {'embedding_dim': 83, 'hidden_dim': 160, 'dropout': 0.20894821299144145, 'lr': 0.003973397629439353, 'batch_size': 32}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.9330, Loss: 0.2924 - Val Acc: 0.7186\n",
      "Trial 13 Done: Val Accuracy = 0.7220, Final Loss = 0.2924\n",
      "\n",
      "Trial 14: emb=81, hid=215, drop=0.46, lr=0.00182, batch=16\n",
      "  Epoch 1/30 - Train Acc: 0.5883, Loss: 3.7965 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 2.1342 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.5336 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.4206 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.3704 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.3300 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 1.3009 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.2705 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 1.2488 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6963, Loss: 1.2135 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6961, Loss: 1.1810 - Val Acc: 0.6776\n",
      "  Epoch 12/30 - Train Acc: 0.6953, Loss: 1.1568 - Val Acc: 0.6761\n",
      "  Epoch 13/30 - Train Acc: 0.6951, Loss: 1.1293 - Val Acc: 0.6731\n",
      "  Epoch 14/30 - Train Acc: 0.6952, Loss: 1.1026 - Val Acc: 0.6740\n",
      "  Epoch 15/30 - Train Acc: 0.6964, Loss: 1.0972 - Val Acc: 0.6693\n",
      "  Epoch 16/30 - Train Acc: 0.6991, Loss: 1.0604 - Val Acc: 0.6694\n",
      "  Epoch 17/30 - Train Acc: 0.7052, Loss: 1.0343 - Val Acc: 0.6683\n",
      "  Epoch 18/30 - Train Acc: 0.7125, Loss: 1.0154 - Val Acc: 0.6689\n",
      "  Epoch 19/30 - Train Acc: 0.7184, Loss: 1.0015 - Val Acc: 0.6637\n",
      "  Epoch 20/30 - Train Acc: 0.7242, Loss: 0.9866 - Val Acc: 0.6632\n",
      "  Epoch 21/30 - Train Acc: 0.7307, Loss: 0.9674 - Val Acc: 0.6592\n",
      "  Epoch 22/30 - Train Acc: 0.7359, Loss: 0.9389 - Val Acc: 0.6552\n",
      "  Epoch 23/30 - Train Acc: 0.7410, Loss: 0.9158 - Val Acc: 0.6660\n",
      "  Epoch 24/30 - Train Acc: 0.7475, Loss: 0.8950 - Val Acc: 0.6612\n",
      "  Epoch 25/30 - Train Acc: 0.7580, Loss: 0.8786 - Val Acc: 0.6680\n",
      "  Epoch 26/30 - Train Acc: 0.7674, Loss: 0.8454 - Val Acc: 0.6810\n",
      "  Epoch 27/30 - Train Acc: 0.7811, Loss: 0.8174 - Val Acc: 0.6805\n",
      "  Epoch 28/30 - Train Acc: 0.7955, Loss: 0.7868 - Val Acc: 0.6802\n",
      "  Epoch 29/30 - Train Acc: 0.8068, Loss: 0.7638 - Val Acc: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:53:31,363] Trial 13 finished with value: 0.6910126357003026 and parameters: {'embedding_dim': 81, 'hidden_dim': 215, 'dropout': 0.4574868100882938, 'lr': 0.0018158450285380551, 'batch_size': 16}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.8174, Loss: 0.7331 - Val Acc: 0.6910\n",
      "Trial 14 Done: Val Accuracy = 0.6910, Final Loss = 0.7331\n",
      "\n",
      "Trial 15: emb=93, hid=167, drop=0.22, lr=0.00235, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.2436, Loss: 4.4465 - Val Acc: 0.4211\n",
      "  Epoch 2/30 - Train Acc: 0.4898, Loss: 3.9509 - Val Acc: 0.5769\n",
      "  Epoch 3/30 - Train Acc: 0.6169, Loss: 3.3827 - Val Acc: 0.5924\n",
      "  Epoch 4/30 - Train Acc: 0.6697, Loss: 2.8108 - Val Acc: 0.6551\n",
      "  Epoch 5/30 - Train Acc: 0.6885, Loss: 2.3023 - Val Acc: 0.6760\n",
      "  Epoch 6/30 - Train Acc: 0.6941, Loss: 1.9279 - Val Acc: 0.6770\n",
      "  Epoch 7/30 - Train Acc: 0.6956, Loss: 1.6899 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.5393 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 1.4510 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 1.3897 - Val Acc: 0.6783\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 1.3490 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6961, Loss: 1.3166 - Val Acc: 0.6782\n",
      "  Epoch 13/30 - Train Acc: 0.6959, Loss: 1.2878 - Val Acc: 0.6773\n",
      "  Epoch 14/30 - Train Acc: 0.6960, Loss: 1.2573 - Val Acc: 0.6772\n",
      "  Epoch 15/30 - Train Acc: 0.6960, Loss: 1.2412 - Val Acc: 0.6770\n",
      "  Epoch 16/30 - Train Acc: 0.6964, Loss: 1.2145 - Val Acc: 0.6769\n",
      "  Epoch 17/30 - Train Acc: 0.6971, Loss: 1.1980 - Val Acc: 0.6763\n",
      "  Epoch 18/30 - Train Acc: 0.6979, Loss: 1.1671 - Val Acc: 0.6761\n",
      "  Epoch 19/30 - Train Acc: 0.6983, Loss: 1.1483 - Val Acc: 0.6755\n",
      "  Epoch 20/30 - Train Acc: 0.6990, Loss: 1.1271 - Val Acc: 0.6753\n",
      "  Epoch 21/30 - Train Acc: 0.6994, Loss: 1.1084 - Val Acc: 0.6734\n",
      "  Epoch 22/30 - Train Acc: 0.7002, Loss: 1.0909 - Val Acc: 0.6747\n",
      "  Epoch 23/30 - Train Acc: 0.7010, Loss: 1.0625 - Val Acc: 0.6710\n",
      "  Epoch 24/30 - Train Acc: 0.7021, Loss: 1.0404 - Val Acc: 0.6726\n",
      "  Epoch 25/30 - Train Acc: 0.7068, Loss: 1.0145 - Val Acc: 0.6753\n",
      "  Epoch 26/30 - Train Acc: 0.7192, Loss: 0.9877 - Val Acc: 0.6766\n",
      "  Epoch 27/30 - Train Acc: 0.7328, Loss: 0.9651 - Val Acc: 0.6844\n",
      "  Epoch 28/30 - Train Acc: 0.7420, Loss: 0.9356 - Val Acc: 0.6841\n",
      "  Epoch 29/30 - Train Acc: 0.7482, Loss: 0.9089 - Val Acc: 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:55:07,092] Trial 14 finished with value: 0.6863142907990746 and parameters: {'embedding_dim': 93, 'hidden_dim': 167, 'dropout': 0.21518333194611458, 'lr': 0.002354646328328524, 'batch_size': 64}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.7536, Loss: 0.8839 - Val Acc: 0.6863\n",
      "Trial 15 Done: Val Accuracy = 0.6863, Final Loss = 0.8839\n",
      "\n",
      "Trial 16: emb=90, hid=195, drop=0.43, lr=0.00195, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.3983, Loss: 4.2370 - Val Acc: 0.6152\n",
      "  Epoch 2/30 - Train Acc: 0.6559, Loss: 3.2885 - Val Acc: 0.6745\n",
      "  Epoch 3/30 - Train Acc: 0.6942, Loss: 2.3636 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.7781 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.5238 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.4307 - Val Acc: 0.6785\n",
      "  Epoch 7/30 - Train Acc: 0.6963, Loss: 1.3734 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.3353 - Val Acc: 0.6785\n",
      "  Epoch 9/30 - Train Acc: 0.6963, Loss: 1.3030 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 1.2747 - Val Acc: 0.6783\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 1.2470 - Val Acc: 0.6781\n",
      "  Epoch 12/30 - Train Acc: 0.6961, Loss: 1.2191 - Val Acc: 0.6771\n",
      "  Epoch 13/30 - Train Acc: 0.6959, Loss: 1.1904 - Val Acc: 0.6775\n",
      "  Epoch 14/30 - Train Acc: 0.6957, Loss: 1.1591 - Val Acc: 0.6761\n",
      "  Epoch 15/30 - Train Acc: 0.6956, Loss: 1.1307 - Val Acc: 0.6738\n",
      "  Epoch 16/30 - Train Acc: 0.6956, Loss: 1.0961 - Val Acc: 0.6720\n",
      "  Epoch 17/30 - Train Acc: 0.6989, Loss: 1.0605 - Val Acc: 0.6718\n",
      "  Epoch 18/30 - Train Acc: 0.7146, Loss: 1.0257 - Val Acc: 0.6807\n",
      "  Epoch 19/30 - Train Acc: 0.7303, Loss: 0.9861 - Val Acc: 0.6855\n",
      "  Epoch 20/30 - Train Acc: 0.7413, Loss: 0.9438 - Val Acc: 0.6886\n",
      "  Epoch 21/30 - Train Acc: 0.7526, Loss: 0.9057 - Val Acc: 0.6949\n",
      "  Epoch 22/30 - Train Acc: 0.7648, Loss: 0.8631 - Val Acc: 0.6961\n",
      "  Epoch 23/30 - Train Acc: 0.7809, Loss: 0.8207 - Val Acc: 0.6980\n",
      "  Epoch 24/30 - Train Acc: 0.7987, Loss: 0.7799 - Val Acc: 0.7019\n",
      "  Epoch 25/30 - Train Acc: 0.8125, Loss: 0.7462 - Val Acc: 0.7063\n",
      "  Epoch 26/30 - Train Acc: 0.8253, Loss: 0.7088 - Val Acc: 0.7048\n",
      "  Epoch 27/30 - Train Acc: 0.8355, Loss: 0.6713 - Val Acc: 0.7014\n",
      "  Epoch 28/30 - Train Acc: 0.8436, Loss: 0.6427 - Val Acc: 0.7025\n",
      "  Epoch 29/30 - Train Acc: 0.8511, Loss: 0.6174 - Val Acc: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:56:22,375] Trial 15 finished with value: 0.7062822566292934 and parameters: {'embedding_dim': 90, 'hidden_dim': 195, 'dropout': 0.4285579688745075, 'lr': 0.001953805143343164, 'batch_size': 32}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.8569, Loss: 0.5953 - Val Acc: 0.6997\n",
      "Trial 16 Done: Val Accuracy = 0.7063, Final Loss = 0.5953\n",
      "\n",
      "Trial 17: emb=86, hid=226, drop=0.50, lr=0.00048, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.1151, Loss: 4.6003 - Val Acc: 0.2494\n",
      "  Epoch 2/30 - Train Acc: 0.2913, Loss: 4.4255 - Val Acc: 0.3178\n",
      "  Epoch 3/30 - Train Acc: 0.3709, Loss: 4.2936 - Val Acc: 0.4039\n",
      "  Epoch 4/30 - Train Acc: 0.4650, Loss: 4.1620 - Val Acc: 0.5301\n",
      "  Epoch 5/30 - Train Acc: 0.5367, Loss: 4.0257 - Val Acc: 0.5613\n",
      "  Epoch 6/30 - Train Acc: 0.5833, Loss: 3.8853 - Val Acc: 0.6008\n",
      "  Epoch 7/30 - Train Acc: 0.6115, Loss: 3.7437 - Val Acc: 0.6240\n",
      "  Epoch 8/30 - Train Acc: 0.6355, Loss: 3.5992 - Val Acc: 0.6238\n",
      "  Epoch 9/30 - Train Acc: 0.6478, Loss: 3.4506 - Val Acc: 0.6393\n",
      "  Epoch 10/30 - Train Acc: 0.6576, Loss: 3.3105 - Val Acc: 0.6397\n",
      "  Epoch 11/30 - Train Acc: 0.6675, Loss: 3.1628 - Val Acc: 0.6573\n",
      "  Epoch 12/30 - Train Acc: 0.6730, Loss: 3.0240 - Val Acc: 0.6580\n",
      "  Epoch 13/30 - Train Acc: 0.6781, Loss: 2.8862 - Val Acc: 0.6615\n",
      "  Epoch 14/30 - Train Acc: 0.6827, Loss: 2.7568 - Val Acc: 0.6661\n",
      "  Epoch 15/30 - Train Acc: 0.6870, Loss: 2.6294 - Val Acc: 0.6703\n",
      "  Epoch 16/30 - Train Acc: 0.6900, Loss: 2.5097 - Val Acc: 0.6737\n",
      "  Epoch 17/30 - Train Acc: 0.6919, Loss: 2.3997 - Val Acc: 0.6734\n",
      "  Epoch 18/30 - Train Acc: 0.6931, Loss: 2.2933 - Val Acc: 0.6755\n",
      "  Epoch 19/30 - Train Acc: 0.6941, Loss: 2.1999 - Val Acc: 0.6766\n",
      "  Epoch 20/30 - Train Acc: 0.6947, Loss: 2.1119 - Val Acc: 0.6772\n",
      "  Epoch 21/30 - Train Acc: 0.6950, Loss: 2.0300 - Val Acc: 0.6778\n",
      "  Epoch 22/30 - Train Acc: 0.6950, Loss: 1.9519 - Val Acc: 0.6773\n",
      "  Epoch 23/30 - Train Acc: 0.6952, Loss: 1.8768 - Val Acc: 0.6781\n",
      "  Epoch 24/30 - Train Acc: 0.6955, Loss: 1.8165 - Val Acc: 0.6776\n",
      "  Epoch 25/30 - Train Acc: 0.6955, Loss: 1.7633 - Val Acc: 0.6776\n",
      "  Epoch 26/30 - Train Acc: 0.6956, Loss: 1.7122 - Val Acc: 0.6780\n",
      "  Epoch 27/30 - Train Acc: 0.6958, Loss: 1.6689 - Val Acc: 0.6779\n",
      "  Epoch 28/30 - Train Acc: 0.6958, Loss: 1.6276 - Val Acc: 0.6780\n",
      "  Epoch 29/30 - Train Acc: 0.6959, Loss: 1.5962 - Val Acc: 0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:57:27,895] Trial 16 finished with value: 0.6784125289197366 and parameters: {'embedding_dim': 86, 'hidden_dim': 226, 'dropout': 0.4988813209001345, 'lr': 0.0004790178925101501, 'batch_size': 64}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6960, Loss: 1.5695 - Val Acc: 0.6784\n",
      "Trial 17 Done: Val Accuracy = 0.6784, Final Loss = 1.5695\n",
      "\n",
      "Trial 18: emb=98, hid=221, drop=0.48, lr=0.00045, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.1870, Loss: 4.5408 - Val Acc: 0.3144\n",
      "  Epoch 2/30 - Train Acc: 0.4243, Loss: 4.2775 - Val Acc: 0.4867\n",
      "  Epoch 3/30 - Train Acc: 0.5621, Loss: 4.0296 - Val Acc: 0.5534\n",
      "  Epoch 4/30 - Train Acc: 0.6270, Loss: 3.7733 - Val Acc: 0.6356\n",
      "  Epoch 5/30 - Train Acc: 0.6508, Loss: 3.5120 - Val Acc: 0.6390\n",
      "  Epoch 6/30 - Train Acc: 0.6647, Loss: 3.2524 - Val Acc: 0.6507\n",
      "  Epoch 7/30 - Train Acc: 0.6770, Loss: 3.0003 - Val Acc: 0.6590\n",
      "  Epoch 8/30 - Train Acc: 0.6859, Loss: 2.7602 - Val Acc: 0.6723\n",
      "  Epoch 9/30 - Train Acc: 0.6917, Loss: 2.5402 - Val Acc: 0.6744\n",
      "  Epoch 10/30 - Train Acc: 0.6945, Loss: 2.3408 - Val Acc: 0.6768\n",
      "  Epoch 11/30 - Train Acc: 0.6956, Loss: 2.1689 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 2.0202 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 1.8894 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 1.7819 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 1.6987 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 1.6252 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 1.5673 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 1.5221 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 1.4854 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 1.4488 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 1.4240 - Val Acc: 0.6783\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 1.4002 - Val Acc: 0.6783\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 1.3770 - Val Acc: 0.6784\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 1.3577 - Val Acc: 0.6783\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 1.3427 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 1.3261 - Val Acc: 0.6782\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 1.3094 - Val Acc: 0.6783\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 1.2959 - Val Acc: 0.6782\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 1.2831 - Val Acc: 0.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:58:43,787] Trial 17 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 98, 'hidden_dim': 221, 'dropout': 0.47614192308589415, 'lr': 0.0004461463011943076, 'batch_size': 32}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 1.2709 - Val Acc: 0.6784\n",
      "Trial 18 Done: Val Accuracy = 0.6784, Final Loss = 1.2709\n",
      "\n",
      "Trial 19: emb=100, hid=241, drop=0.46, lr=0.00369, batch=64\n",
      "  Epoch 1/30 - Train Acc: 0.5592, Loss: 4.2047 - Val Acc: 0.5674\n",
      "  Epoch 2/30 - Train Acc: 0.6781, Loss: 3.2399 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 2.2926 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.6983 - Val Acc: 0.6784\n",
      "  Epoch 5/30 - Train Acc: 0.6962, Loss: 1.4696 - Val Acc: 0.6784\n",
      "  Epoch 6/30 - Train Acc: 0.6962, Loss: 1.3829 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 1.3421 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 1.3044 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 1.2667 - Val Acc: 0.6783\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 1.2362 - Val Acc: 0.6778\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 1.1994 - Val Acc: 0.6776\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 1.1594 - Val Acc: 0.6775\n",
      "  Epoch 13/30 - Train Acc: 0.6963, Loss: 1.1201 - Val Acc: 0.6762\n",
      "  Epoch 14/30 - Train Acc: 0.7031, Loss: 1.0756 - Val Acc: 0.6820\n",
      "  Epoch 15/30 - Train Acc: 0.7236, Loss: 1.0279 - Val Acc: 0.6834\n",
      "  Epoch 16/30 - Train Acc: 0.7354, Loss: 0.9808 - Val Acc: 0.6819\n",
      "  Epoch 17/30 - Train Acc: 0.7459, Loss: 0.9331 - Val Acc: 0.6827\n",
      "  Epoch 18/30 - Train Acc: 0.7628, Loss: 0.8932 - Val Acc: 0.6935\n",
      "  Epoch 19/30 - Train Acc: 0.7841, Loss: 0.8456 - Val Acc: 0.6949\n",
      "  Epoch 20/30 - Train Acc: 0.8019, Loss: 0.7961 - Val Acc: 0.6940\n",
      "  Epoch 21/30 - Train Acc: 0.8168, Loss: 0.7481 - Val Acc: 0.6962\n",
      "  Epoch 22/30 - Train Acc: 0.8295, Loss: 0.7028 - Val Acc: 0.7028\n",
      "  Epoch 23/30 - Train Acc: 0.8383, Loss: 0.6661 - Val Acc: 0.7032\n",
      "  Epoch 24/30 - Train Acc: 0.8466, Loss: 0.6353 - Val Acc: 0.7035\n",
      "  Epoch 25/30 - Train Acc: 0.8546, Loss: 0.6087 - Val Acc: 0.6973\n",
      "  Epoch 26/30 - Train Acc: 0.8619, Loss: 0.5762 - Val Acc: 0.7061\n",
      "  Epoch 27/30 - Train Acc: 0.8680, Loss: 0.5495 - Val Acc: 0.7078\n",
      "  Epoch 28/30 - Train Acc: 0.8755, Loss: 0.5261 - Val Acc: 0.7072\n",
      "  Epoch 29/30 - Train Acc: 0.8818, Loss: 0.5035 - Val Acc: 0.7048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 10:59:55,295] Trial 18 finished with value: 0.7113009432283325 and parameters: {'embedding_dim': 100, 'hidden_dim': 241, 'dropout': 0.45788722886423083, 'lr': 0.0036912383390022407, 'batch_size': 64}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.8868, Loss: 0.4846 - Val Acc: 0.7113\n",
      "Trial 19 Done: Val Accuracy = 0.7113, Final Loss = 0.4846\n",
      "\n",
      "Trial 20: emb=79, hid=239, drop=0.37, lr=0.00013, batch=32\n",
      "  Epoch 1/30 - Train Acc: 0.1411, Loss: 4.5881 - Val Acc: 0.2463\n",
      "  Epoch 2/30 - Train Acc: 0.4914, Loss: 4.4722 - Val Acc: 0.6011\n",
      "  Epoch 3/30 - Train Acc: 0.6258, Loss: 4.3719 - Val Acc: 0.6226\n",
      "  Epoch 4/30 - Train Acc: 0.6524, Loss: 4.2938 - Val Acc: 0.6478\n",
      "  Epoch 5/30 - Train Acc: 0.6741, Loss: 4.2178 - Val Acc: 0.6629\n",
      "  Epoch 6/30 - Train Acc: 0.6898, Loss: 4.1415 - Val Acc: 0.6784\n",
      "  Epoch 7/30 - Train Acc: 0.6962, Loss: 4.0632 - Val Acc: 0.6784\n",
      "  Epoch 8/30 - Train Acc: 0.6962, Loss: 3.9838 - Val Acc: 0.6784\n",
      "  Epoch 9/30 - Train Acc: 0.6962, Loss: 3.9049 - Val Acc: 0.6784\n",
      "  Epoch 10/30 - Train Acc: 0.6962, Loss: 3.8251 - Val Acc: 0.6784\n",
      "  Epoch 11/30 - Train Acc: 0.6962, Loss: 3.7455 - Val Acc: 0.6784\n",
      "  Epoch 12/30 - Train Acc: 0.6962, Loss: 3.6666 - Val Acc: 0.6784\n",
      "  Epoch 13/30 - Train Acc: 0.6962, Loss: 3.5873 - Val Acc: 0.6784\n",
      "  Epoch 14/30 - Train Acc: 0.6962, Loss: 3.5087 - Val Acc: 0.6784\n",
      "  Epoch 15/30 - Train Acc: 0.6962, Loss: 3.4298 - Val Acc: 0.6784\n",
      "  Epoch 16/30 - Train Acc: 0.6962, Loss: 3.3499 - Val Acc: 0.6784\n",
      "  Epoch 17/30 - Train Acc: 0.6962, Loss: 3.2712 - Val Acc: 0.6784\n",
      "  Epoch 18/30 - Train Acc: 0.6962, Loss: 3.1969 - Val Acc: 0.6784\n",
      "  Epoch 19/30 - Train Acc: 0.6962, Loss: 3.1208 - Val Acc: 0.6784\n",
      "  Epoch 20/30 - Train Acc: 0.6962, Loss: 3.0431 - Val Acc: 0.6784\n",
      "  Epoch 21/30 - Train Acc: 0.6962, Loss: 2.9687 - Val Acc: 0.6784\n",
      "  Epoch 22/30 - Train Acc: 0.6962, Loss: 2.8972 - Val Acc: 0.6784\n",
      "  Epoch 23/30 - Train Acc: 0.6962, Loss: 2.8266 - Val Acc: 0.6784\n",
      "  Epoch 24/30 - Train Acc: 0.6962, Loss: 2.7549 - Val Acc: 0.6784\n",
      "  Epoch 25/30 - Train Acc: 0.6962, Loss: 2.6878 - Val Acc: 0.6784\n",
      "  Epoch 26/30 - Train Acc: 0.6962, Loss: 2.6208 - Val Acc: 0.6784\n",
      "  Epoch 27/30 - Train Acc: 0.6962, Loss: 2.5566 - Val Acc: 0.6784\n",
      "  Epoch 28/30 - Train Acc: 0.6962, Loss: 2.4926 - Val Acc: 0.6784\n",
      "  Epoch 29/30 - Train Acc: 0.6962, Loss: 2.4333 - Val Acc: 0.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 11:01:15,797] Trial 19 finished with value: 0.6784481224417156 and parameters: {'embedding_dim': 79, 'hidden_dim': 239, 'dropout': 0.36982765507320664, 'lr': 0.00013294594104599347, 'batch_size': 32}. Best is trial 11 with value: 0.7493860117458623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30/30 - Train Acc: 0.6962, Loss: 2.3777 - Val Acc: 0.6784\n",
      "Trial 20 Done: Val Accuracy = 0.6784, Final Loss = 2.3777\n",
      "\n",
      "Best Trial Hyperparameters:\n",
      "  embedding_dim: 99\n",
      "  hidden_dim: 212\n",
      "  dropout: 0.49925576681424444\n",
      "  lr: 0.004737349647790637\n",
      "  batch_size: 16\n",
      "\n",
      "Final Training with Best Hyperparameters...\n",
      "  Epoch 1/30 - Train Acc: 0.6529, Loss: 2.7485 - Val Acc: 0.6784\n",
      "  Epoch 2/30 - Train Acc: 0.6962, Loss: 1.4366 - Val Acc: 0.6784\n",
      "  Epoch 3/30 - Train Acc: 0.6962, Loss: 1.3562 - Val Acc: 0.6784\n",
      "  Epoch 4/30 - Train Acc: 0.6962, Loss: 1.2936 - Val Acc: 0.6783\n",
      "  Epoch 5/30 - Train Acc: 0.6956, Loss: 1.2223 - Val Acc: 0.6760\n",
      "  Epoch 6/30 - Train Acc: 0.7057, Loss: 1.1405 - Val Acc: 0.6912\n",
      "  Epoch 7/30 - Train Acc: 0.7346, Loss: 1.0428 - Val Acc: 0.6962\n",
      "  Epoch 8/30 - Train Acc: 0.7694, Loss: 0.9185 - Val Acc: 0.7053\n",
      "  Epoch 9/30 - Train Acc: 0.8031, Loss: 0.7945 - Val Acc: 0.7117\n",
      "  Epoch 10/30 - Train Acc: 0.8304, Loss: 0.6917 - Val Acc: 0.7269\n",
      "  Epoch 11/30 - Train Acc: 0.8488, Loss: 0.6106 - Val Acc: 0.7332\n",
      "  Epoch 12/30 - Train Acc: 0.8651, Loss: 0.5446 - Val Acc: 0.7318\n",
      "  Epoch 13/30 - Train Acc: 0.8806, Loss: 0.4822 - Val Acc: 0.7378\n",
      "  Epoch 14/30 - Train Acc: 0.8922, Loss: 0.4328 - Val Acc: 0.7370\n",
      "  Epoch 15/30 - Train Acc: 0.9022, Loss: 0.3926 - Val Acc: 0.7376\n",
      "  Epoch 16/30 - Train Acc: 0.9105, Loss: 0.3548 - Val Acc: 0.7371\n",
      "  Epoch 17/30 - Train Acc: 0.9190, Loss: 0.3175 - Val Acc: 0.7406\n",
      "  Epoch 18/30 - Train Acc: 0.9250, Loss: 0.2907 - Val Acc: 0.7390\n",
      "  Epoch 19/30 - Train Acc: 0.9319, Loss: 0.2626 - Val Acc: 0.7436\n",
      "  Epoch 20/30 - Train Acc: 0.9381, Loss: 0.2386 - Val Acc: 0.7446\n",
      "  Epoch 21/30 - Train Acc: 0.9439, Loss: 0.2131 - Val Acc: 0.7458\n",
      "  Epoch 22/30 - Train Acc: 0.9493, Loss: 0.1916 - Val Acc: 0.7438\n",
      "  Epoch 23/30 - Train Acc: 0.9527, Loss: 0.1779 - Val Acc: 0.7507\n",
      "  Epoch 24/30 - Train Acc: 0.9566, Loss: 0.1615 - Val Acc: 0.7444\n",
      "  Epoch 25/30 - Train Acc: 0.9605, Loss: 0.1448 - Val Acc: 0.7467\n",
      "  Epoch 26/30 - Train Acc: 0.9642, Loss: 0.1314 - Val Acc: 0.7447\n",
      "  Epoch 27/30 - Train Acc: 0.9627, Loss: 0.1334 - Val Acc: 0.7460\n",
      "  Epoch 28/30 - Train Acc: 0.9601, Loss: 0.1413 - Val Acc: 0.7438\n",
      "  Epoch 29/30 - Train Acc: 0.9645, Loss: 0.1264 - Val Acc: 0.7424\n",
      "  Epoch 30/30 - Train Acc: 0.9682, Loss: 0.1148 - Val Acc: 0.7445\n",
      "\n",
      "Final Test Accuracy: 0.7688\n",
      "Model saved to './model/bilstm_attention.pt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "import os\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_json(\"./data/processed/te/train.json\", orient=\"records\", lines=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. Token and Label Index Mapping (renamed)\n",
    "token2idx_a_multi = {token: idx for idx, token in enumerate(set(token for row in df.tokens for token in row), start=1)}\n",
    "token2idx_a_multi[\"<PAD>\"] = 0\n",
    "label2idx_a_multi = {label: idx for idx, label in enumerate(set(label for row in df.tags for label in row), start=1)}\n",
    "label2idx_a_multi[\"<PAD>\"] = 0\n",
    "idx2label_a_multi = {v: k for k, v in label2idx_a_multi.items()}\n",
    "\n",
    "# 3. Encoding Function\n",
    "def encode(row, max_len=150):\n",
    "    token_ids = [token2idx_a_multi[token] for token in row['tokens']]\n",
    "    tag_ids = [label2idx_a_multi[tag] for tag in row['tags']]\n",
    "    pad_len = max_len - len(token_ids)\n",
    "    token_ids += [token2idx_a_multi[\"<PAD>\"]] * pad_len\n",
    "    tag_ids += [label2idx_a_multi[\"<PAD>\"]] * pad_len\n",
    "    return token_ids[:max_len], tag_ids[:max_len]\n",
    "\n",
    "df['encoded'] = df.apply(encode, axis=1)\n",
    "\n",
    "# 4. Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# 5. Dataset\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tokens = [x[0] for x in data.encoded]\n",
    "        self.labels = [x[1] for x in data.encoded]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokens[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "# 6. BiLSTM + Attention Model with improvements\n",
    "class BiLSTMAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, dropout):\n",
    "        super(BiLSTMAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.attn_w = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.attn_context = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.attn_w.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_context.weight)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(emb)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "        u = torch.tanh(self.attn_w(lstm_out))\n",
    "        attn_weights = torch.softmax(self.attn_context(u), dim=1)\n",
    "        attn_applied = lstm_out * attn_weights\n",
    "        out = self.fc(self.dropout(attn_applied))\n",
    "        return out\n",
    "\n",
    "# 7. Train Function\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=30):\n",
    "    model.to(device)\n",
    "    best_val_acc = 0\n",
    "    final_loss = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_correct, train_total = 0, 0\n",
    "\n",
    "        for tokens, labels in train_loader:\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens)\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            mask = labels != 0\n",
    "            train_correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            train_total += mask.sum().item()\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        final_loss = avg_loss\n",
    "\n",
    "        # Validation accuracy\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for tokens, labels in val_loader:\n",
    "                tokens, labels = tokens.to(device), labels.to(device)\n",
    "                outputs = model(tokens)\n",
    "                preds = torch.argmax(outputs, dim=-1)\n",
    "                mask = labels != 0\n",
    "                all_preds.extend(preds[mask].cpu().numpy())\n",
    "                all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        print(f\"  Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}, Loss: {avg_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "    return best_val_acc, final_loss\n",
    "\n",
    "# 8. Optuna Objective\n",
    "def objective(trial):\n",
    "    embedding_dim = trial.suggest_int('embedding_dim', 64, 128)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 128, 256)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    train_loader = DataLoader(TokenDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TokenDataset(val_data), batch_size=batch_size)\n",
    "\n",
    "    model = BiLSTMAttention(len(token2idx_a_multi), len(label2idx_a_multi), embedding_dim, hidden_dim, dropout)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    print(f\"\\nTrial {trial.number + 1}: emb={embedding_dim}, hid={hidden_dim}, drop={dropout:.2f}, lr={lr:.5f}, batch={batch_size}\")\n",
    "    val_acc, final_loss = train_model(model, train_loader, val_loader, optimizer, criterion, device)\n",
    "    print(f\"Trial {trial.number + 1} Done: Val Accuracy = {val_acc:.4f}, Final Loss = {final_loss:.4f}\")\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "# 9. Run Optuna\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler())\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# 10. Best Hyperparameters\n",
    "print(\"\\nBest Trial Hyperparameters:\")\n",
    "for key, val in study.best_params.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "# 11. Final Model Training\n",
    "params = study.best_params\n",
    "train_loader = DataLoader(TokenDataset(train_data), batch_size=params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(TokenDataset(val_data), batch_size=params['batch_size'])\n",
    "test_loader = DataLoader(TokenDataset(test_data), batch_size=params['batch_size'])\n",
    "\n",
    "model = BiLSTMAttention(len(token2idx_a_multi), len(label2idx_a_multi), params['embedding_dim'], params['hidden_dim'], params['dropout'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "print(\"\\nFinal Training with Best Hyperparameters...\")\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=30)\n",
    "\n",
    "# 12. Test Accuracy\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for tokens, labels in test_loader:\n",
    "        tokens, labels = tokens.to(device), labels.to(device)\n",
    "        outputs = model(tokens)\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        mask = labels != 0\n",
    "        all_preds.extend(preds[mask].cpu().numpy())\n",
    "        all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 13. Save Model\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "torch.save(model.state_dict(), './model/bilstm_attention.pt')\n",
    "print(\"Model saved to './model/bilstm_attention.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e67c1195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved token2idx_a_multi and label2idx_a_multi to './model/'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create a directory if it doesn't exist\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "# Save token2idx_a_multi\n",
    "with open('./model/token2idx_a_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(token2idx_a_multi, f)\n",
    "\n",
    "# Save label2idx_a_multi\n",
    "with open('./model/label2idx_a_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(label2idx_a_multi, f)\n",
    "\n",
    "print(\"Saved token2idx_a_multi and label2idx_a_multi to './model/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23e0ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ([33882, 35887, 24163, 830, 10594, 32539, 3554...\n",
       "1    ([36588, 11186, 19350, 10737, 18230, 2163, 439...\n",
       "2    ([34551, 5132, 22017, 16906, 13196, 19054, 216...\n",
       "3    ([22498, 19692, 22660, 29501, 33075, 2192, 294...\n",
       "4    ([20079, 23821, 22660, 16903, 2756, 18104, 542...\n",
       "Name: encoded, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9018d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMAttention(\n",
      "  (embedding): Embedding(38338, 99, padding_idx=0)\n",
      "  (bilstm): LSTM(99, 212, batch_first=True, bidirectional=True)\n",
      "  (layer_norm): LayerNorm((424,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn_w): Linear(in_features=424, out_features=212, bias=True)\n",
      "  (attn_context): Linear(in_features=212, out_features=1, bias=False)\n",
      "  (dropout): Dropout(p=0.49925576681424444, inplace=False)\n",
      "  (fc): Linear(in_features=424, out_features=107, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4241a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "             I-NATURAL_EVENT.CYCLONE       0.50      0.38      0.43         8\n",
      "     B-MAN_MADE_EVENT.NORMAL_BOMBING       0.22      0.13      0.17        15\n",
      "                          B-TIME-ARG       0.62      0.59      0.60       255\n",
      "              B-MAN_MADE_EVENT.RIOTS       0.00      0.00      0.00         4\n",
      "                     B-EPICENTRE-ARG       0.25      0.12      0.17         8\n",
      "         I-NATURAL_EVENT.HAIL_STORMS       1.00      0.17      0.29         6\n",
      "   I-MAN_MADE_EVENT.SURGICAL_STRIKES       1.00      0.50      0.67         2\n",
      "         B-NATURAL_EVENT.FOREST_FIRE       0.38      0.14      0.21        21\n",
      "   B-MAN_MADE_EVENT.TERRORIST_ATTACK       0.82      0.53      0.64        17\n",
      "           I-NATURAL_EVENT.COLD_WAVE       1.00      0.50      0.67         2\n",
      "                         B-SPEED-ARG       0.67      0.50      0.57         8\n",
      "                     I-MAGNITUDE-ARG       0.81      0.66      0.72        32\n",
      "          B-MAN_MADE_EVENT.SHOOT_OUT       0.57      0.53      0.55        30\n",
      "                         I-SPEED-ARG       0.71      0.47      0.57        32\n",
      "    I-MAN_MADE_EVENT.TRAIN_COLLISION       1.00      0.25      0.40         4\n",
      "           I-NATURAL_EVENT.HEAT_WAVE       0.50      0.50      0.50         8\n",
      "    I-MAN_MADE_EVENT.AVIATION_HAZARD       0.00      0.00      0.00         5\n",
      "                    B-CASUALTIES-ARG       0.51      0.49      0.50       421\n",
      "              B-MAN_MADE_EVENT.CRIME       0.69      0.59      0.64        46\n",
      "                 I-AFTER_EFFECTS-ARG       0.45      0.38      0.41      1137\n",
      "                        B-REASON-ARG       0.22      0.14      0.17        99\n",
      "     I-MAN_MADE_EVENT.SUICIDE_ATTACK       0.58      0.65      0.61        17\n",
      "            I-NATURAL_EVENT.BLIZZARD       0.50      1.00      0.67         3\n",
      "          B-NATURAL_EVENT.LAND_SLIDE       0.72      0.65      0.69        55\n",
      "               I-NATURAL_EVENT.STORM       0.00      0.00      0.00         7\n",
      "             B-NATURAL_EVENT.CYCLONE       0.44      0.63      0.52        38\n",
      "                     I-INTENSITY-ARG       0.50      0.38      0.43        52\n",
      "                     I-EPICENTRE-ARG       0.85      0.47      0.60        47\n",
      "          B-NATURAL_EVENT.EARTHQUAKE       0.90      0.90      0.90        83\n",
      "          I-NATURAL_EVENT.LAND_SLIDE       0.50      0.05      0.09        20\n",
      "                        I-REASON-ARG       0.31      0.16      0.21       419\n",
      "                         B-PLACE-ARG       0.51      0.49      0.50       654\n",
      "     I-MAN_MADE_EVENT.NORMAL_BOMBING       0.25      0.20      0.22        10\n",
      "             I-NATURAL_EVENT.VOLCANO       0.43      0.30      0.35        10\n",
      "   I-NATURAL_EVENT.LIMNIC_ERRUPTIONS       0.00      0.00      0.00         1\n",
      "           B-NATURAL_EVENT.HURRICANE       0.33      0.29      0.31        17\n",
      "   B-NATURAL_EVENT.LIMNIC_ERRUPTIONS       0.00      0.00      0.00         1\n",
      "            B-NATURAL_EVENT.BLIZZARD       0.60      1.00      0.75         6\n",
      "I-MAN_MADE_EVENT.VEHICULAR_COLLISION       0.22      0.15      0.18        13\n",
      "  B-MAN_MADE_EVENT.TRANSPORT_HAZARDS       0.28      0.20      0.23        35\n",
      "                          I-TYPE-ARG       0.50      0.50      0.50         2\n",
      "                         B-DEPTH-ARG       0.25      0.10      0.14        10\n",
      "           I-NATURAL_EVENT.HURRICANE       0.00      0.00      0.00         3\n",
      "              I-NATURAL_EVENT.FLOODS       0.20      0.25      0.22         4\n",
      "                 B-AFTER_EFFECTS-ARG       0.29      0.25      0.27       215\n",
      "             B-NATURAL_EVENT.TSUNAMI       0.75      0.90      0.82        10\n",
      "         I-NATURAL_EVENT.FOREST_FIRE       0.57      0.17      0.27        23\n",
      "              I-MAN_MADE_EVENT.CRIME       0.50      0.13      0.21        15\n",
      "            I-NATURAL_EVENT.EPIDEMIC       0.00      0.00      0.00         9\n",
      "             I-NATURAL_EVENT.TSUNAMI       0.67      0.50      0.57         4\n",
      "                         I-PLACE-ARG       0.62      0.46      0.53      1295\n",
      "                    I-CASUALTIES-ARG       0.62      0.59      0.61      1959\n",
      "   I-MAN_MADE_EVENT.TERRORIST_ATTACK       0.57      1.00      0.73         4\n",
      "                         I-DEPTH-ARG       0.50      0.19      0.28        31\n",
      "          I-MAN_MADE_EVENT.SHOOT_OUT       0.91      0.59      0.71        17\n",
      "          I-MAN_MADE_EVENT.ACCIDENTS       0.50      0.19      0.27        43\n",
      "                          B-NAME-ARG       0.46      0.23      0.31        52\n",
      "     B-MAN_MADE_EVENT.SUICIDE_ATTACK       0.53      0.53      0.53        19\n",
      "          B-MAN_MADE_EVENT.ACCIDENTS       0.50      0.37      0.43        86\n",
      "             B-NATURAL_EVENT.VOLCANO       0.42      0.36      0.38        14\n",
      "B-MAN_MADE_EVENT.VEHICULAR_COLLISION       0.37      0.49      0.42        51\n",
      "  I-MAN_MADE_EVENT.TRANSPORT_HAZARDS       0.19      0.08      0.11        38\n",
      "               I-MAN_MADE_EVENT.FIRE       0.59      0.55      0.56        44\n",
      "               B-NATURAL_EVENT.STORM       0.10      0.09      0.10        22\n",
      "              B-NATURAL_EVENT.FLOODS       0.59      0.90      0.72        42\n",
      "           B-NATURAL_EVENT.COLD_WAVE       0.50      0.33      0.40         3\n",
      "    B-MAN_MADE_EVENT.TRAIN_COLLISION       0.40      0.20      0.27        10\n",
      "                     B-MAGNITUDE-ARG       0.71      0.40      0.51        25\n",
      "   B-MAN_MADE_EVENT.SURGICAL_STRIKES       0.50      0.67      0.57         9\n",
      "         B-NATURAL_EVENT.HAIL_STORMS       0.75      0.69      0.72        13\n",
      "             I-NATURAL_EVENT.TORNADO       0.00      0.00      0.00         1\n",
      "            B-NATURAL_EVENT.EPIDEMIC       0.00      0.00      0.00        11\n",
      "B-MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT       0.35      0.50      0.41        12\n",
      "             B-NATURAL_EVENT.DROUGHT       0.00      0.00      0.00         5\n",
      "               B-MAN_MADE_EVENT.FIRE       0.65      0.60      0.63       111\n",
      "I-MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT       0.00      0.00      0.00         9\n",
      "                                   O       0.84      0.90      0.87     20096\n",
      "    B-MAN_MADE_EVENT.AVIATION_HAZARD       0.14      0.14      0.14         7\n",
      "                          I-NAME-ARG       0.00      0.00      0.00        28\n",
      "           B-NATURAL_EVENT.HEAT_WAVE       0.90      0.72      0.80        25\n",
      "             I-NATURAL_EVENT.DROUGHT       0.00      0.00      0.00         3\n",
      "                     B-INTENSITY-ARG       0.31      0.18      0.23        22\n",
      "          B-NATURAL_EVENT.AVALANCHES       0.75      0.75      0.75        16\n",
      "            B-NATURAL_EVENT.PANDEMIC       0.00      0.00      0.00         8\n",
      "                          I-TIME-ARG       0.63      0.60      0.61       294\n",
      "                   B-PARTICIPANT-ARG       0.35      0.26      0.30        46\n",
      "                   I-PARTICIPANT-ARG       0.30      0.22      0.25        55\n",
      "             B-NATURAL_EVENT.TORNADO       0.90      0.82      0.86        11\n",
      "          I-NATURAL_EVENT.EARTHQUAKE       0.93      0.86      0.89        29\n",
      "                          B-TYPE-ARG       0.60      0.50      0.55         6\n",
      "\n",
      "                           micro avg       0.77      0.77      0.77     28515\n",
      "                           macro avg       0.46      0.38      0.40     28515\n",
      "                        weighted avg       0.75      0.77      0.76     28515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kotav\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kotav\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kotav\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get only labels present in your predictions (excluding 0 for <PAD>)\n",
    "used_label_ids = sorted(set(all_labels))  # this includes only labels in the test set\n",
    "used_label_ids = [x for x in used_label_ids if x != 0]  # remove padding\n",
    "\n",
    "# Now get corresponding label names\n",
    "target_names = [idx2label[i] for i in used_label_ids]\n",
    "\n",
    "# Print Report\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, labels=used_label_ids, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "579e71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 106\n",
      "Unique labels: {'I-NATURAL_EVENT.CYCLONE', 'B-MAN_MADE_EVENT.NORMAL_BOMBING', 'B-TIME-ARG', 'B-MAN_MADE_EVENT.RIOTS', 'B-EPICENTRE-ARG', 'B-NATURAL_EVENT.SEISMIC_RISK', 'I-NATURAL_EVENT.HAIL_STORMS', 'I-MAN_MADE_EVENT.ARMED_CONFLICTS', 'I-MAN_MADE_EVENT.SURGICAL_STRIKES', 'B-NATURAL_EVENT.FOREST_FIRE', 'B-MAN_MADE_EVENT.TERRORIST_ATTACK', 'I-NATURAL_EVENT.COLD_WAVE', 'B-SPEED-ARG', 'I-NATURAL_EVENT.AVALANCHES', 'I-MAGNITUDE-ARG', 'B-NATURAL_EVENT.HEAVY_RAINFALL', 'B-MAN_MADE_EVENT.SHOOT_OUT', 'I-SPEED-ARG', 'I-MAN_MADE_EVENT.TRAIN_COLLISION', 'I-NATURAL_EVENT.HEAT_WAVE', 'I-MAN_MADE_EVENT.AVIATION_HAZARD', 'B-MAN_MADE_EVENT.ARMED_CONFLICTS', 'B-CASUALTIES-ARG', 'B-MAN_MADE_EVENT.CRIME', 'I-MAN_MADE_EVENT.MISCELLANEOUS', 'I-AFTER_EFFECTS-ARG', 'B-NATURAL_EVENT.FAMINE', 'B-REASON-ARG', 'I-MAN_MADE_EVENT.SUICIDE_ATTACK', 'I-NATURAL_EVENT.BLIZZARD', 'B-NATURAL_EVENT.LAND_SLIDE', 'I-NATURAL_EVENT.STORM', 'B-NATURAL_EVENT.CYCLONE', 'I-INTENSITY-ARG', 'I-EPICENTRE-ARG', 'B-NATURAL_EVENT.EARTHQUAKE', 'I-NATURAL_EVENT.LAND_SLIDE', 'I-REASON-ARG', 'B-PLACE-ARG', 'I-MAN_MADE_EVENT.NORMAL_BOMBING', 'I-MAN_MADE_EVENT.RIOTS', 'I-NATURAL_EVENT.VOLCANO', 'I-NATURAL_EVENT.LIMNIC_ERRUPTIONS', 'B-NATURAL_EVENT.HURRICANE', 'I-NATURAL_EVENT.ROCK_FALL', 'B-NATURAL_EVENT.LIMNIC_ERRUPTIONS', 'B-NATURAL_EVENT.BLIZZARD', 'I-MAN_MADE_EVENT.VEHICULAR_COLLISION', 'B-MAN_MADE_EVENT.TRANSPORT_HAZARDS', 'I-TYPE-ARG', 'B-DEPTH-ARG', 'I-NATURAL_EVENT.HURRICANE', 'I-NATURAL_EVENT.FLOODS', 'B-MAN_MADE_EVENT.MISCELLANEOUS', 'I-NATURAL_EVENT.HEAVY_RAINFALL', 'B-AFTER_EFFECTS-ARG', 'B-NATURAL_EVENT.TSUNAMI', 'I-NATURAL_EVENT.FOREST_FIRE', 'B-TEMPERATURE-ARG', 'I-MAN_MADE_EVENT.CRIME', 'I-NATURAL_EVENT.EPIDEMIC', 'I-NATURAL_EVENT.TSUNAMI', 'I-PLACE-ARG', 'I-CASUALTIES-ARG', 'I-MAN_MADE_EVENT.TERRORIST_ATTACK', 'I-DEPTH-ARG', 'B-NATURAL_EVENT.ROCK_FALL', 'I-NATURAL_EVENT.PANDEMIC', 'I-MAN_MADE_EVENT.SHOOT_OUT', 'I-TEMPERATURE-ARG', 'I-MAN_MADE_EVENT.ACCIDENTS', 'B-NAME-ARG', 'B-MAN_MADE_EVENT.SUICIDE_ATTACK', 'I-NATURAL_EVENT.FAMINE', 'B-MAN_MADE_EVENT.ACCIDENTS', 'B-NATURAL_EVENT.VOLCANO', 'B-MAN_MADE_EVENT.VEHICULAR_COLLISION', 'I-MAN_MADE_EVENT.TRANSPORT_HAZARDS', 'I-MAN_MADE_EVENT.FIRE', 'B-NATURAL_EVENT.STORM', 'B-NATURAL_EVENT.FLOODS', 'B-NATURAL_EVENT.COLD_WAVE', 'B-MAN_MADE_EVENT.TRAIN_COLLISION', 'B-MAGNITUDE-ARG', 'B-MAN_MADE_EVENT.SURGICAL_STRIKES', 'B-NATURAL_EVENT.HAIL_STORMS', 'I-NATURAL_EVENT.TORNADO', 'B-NATURAL_EVENT.EPIDEMIC', 'B-MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT', 'B-NATURAL_EVENT.DROUGHT', 'B-MAN_MADE_EVENT.FIRE', 'I-MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT', 'O', 'B-MAN_MADE_EVENT.AVIATION_HAZARD', 'I-NAME-ARG', 'B-NATURAL_EVENT.HEAT_WAVE', 'I-NATURAL_EVENT.DROUGHT', 'B-INTENSITY-ARG', 'B-NATURAL_EVENT.AVALANCHES', 'B-NATURAL_EVENT.PANDEMIC', 'I-TIME-ARG', 'B-PARTICIPANT-ARG', 'I-PARTICIPANT-ARG', 'B-NATURAL_EVENT.TORNADO', 'I-NATURAL_EVENT.EARTHQUAKE', 'B-TYPE-ARG'}\n"
     ]
    }
   ],
   "source": [
    "# Flatten all tags into one big list\n",
    "all_labels = [label for row in df['tags'] for label in row]\n",
    "\n",
    "# Get the unique labels\n",
    "unique_labels = set(all_labels)\n",
    "\n",
    "# Print count and the unique labels\n",
    "print(\"Number of unique labels:\", len(unique_labels))\n",
    "print(\"Unique labels:\", unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "403df599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(model, sentence_tokens, token2idx, idx2label, max_len=150):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Encode input\n",
    "    token_ids = [token2idx.get(token, token2idx[\"<PAD>\"]) for token in sentence_tokens]\n",
    "    pad_len = max_len - len(token_ids)\n",
    "    token_ids += [token2idx[\"<PAD>\"]] * pad_len\n",
    "    token_ids = token_ids[:max_len]\n",
    "\n",
    "    input_tensor = torch.tensor([token_ids]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        preds = torch.argmax(outputs, dim=-1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Convert predicted indices to labels and remove padding\n",
    "    predicted_tags = [idx2label[idx] for idx in preds[:len(sentence_tokens)]]\n",
    "    return list(zip(sentence_tokens, predicted_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c760b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_sentence(model, sentence, token2idx, idx2label, max_len=50):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize by space (like in your train.json)\n",
    "    tokens = sentence.strip().split()\n",
    "\n",
    "    # Encode\n",
    "    token_ids = [token2idx.get(token, token2idx[\"<PAD>\"]) for token in tokens]\n",
    "    pad_len = max_len - len(token_ids)\n",
    "    token_ids += [token2idx[\"<PAD>\"]] * pad_len\n",
    "    token_ids = token_ids[:max_len]\n",
    "\n",
    "    input_tensor = torch.tensor([token_ids]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        preds = torch.argmax(outputs, dim=-1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    predicted_tags = [idx2label[idx] for idx in preds[:len(tokens)]]\n",
    "    return list(zip(tokens, predicted_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2d2ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "అగ్ని      -> B-MAN_MADE_EVENT.FIRE\n",
      "ప్రమాదం    -> I-MAN_MADE_EVENT.FIRE\n",
      "భవనాన్ని   -> O\n",
      "భస్మం      -> O\n",
      "చేసింది.   -> O\n",
      "చనిపోయిన   -> B-CASUALTIES-ARG\n",
      "వారి       -> O\n",
      "సంఖ్య      -> I-CASUALTIES-ARG\n",
      "పెరుగుతోంది. -> I-CASUALTIES-ARG\n"
     ]
    }
   ],
   "source": [
    "sample_sentence =  \"\"\"అగ్ని ప్రమాదం భవనాన్ని భస్మం చేసింది. చనిపోయిన వారి సంఖ్య పెరుగుతోంది.\"\"\"\n",
    "\n",
    "predictions = predict_from_sentence(model, sample_sentence, token2idx, idx2label)\n",
    "\n",
    "for token, tag in predictions:\n",
    "    print(f\"{token:10} -> {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4ee4e",
   "metadata": {},
   "source": [
    "## without autotune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09592af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/50, Loss: 179.6452, Train Acc: 0.6736, Val Acc: 0.7126\n",
      "Epoch 2/50, Loss: 124.5848, Train Acc: 0.7264, Val Acc: 0.7273\n",
      "Epoch 3/50, Loss: 108.8451, Train Acc: 0.7435, Val Acc: 0.7398\n",
      "Epoch 4/50, Loss: 96.6145, Train Acc: 0.7617, Val Acc: 0.7436\n",
      "Epoch 5/50, Loss: 86.8606, Train Acc: 0.7779, Val Acc: 0.7506\n",
      "Epoch 6/50, Loss: 78.1002, Train Acc: 0.7958, Val Acc: 0.7573\n",
      "Epoch 7/50, Loss: 70.6709, Train Acc: 0.8109, Val Acc: 0.7610\n",
      "Epoch 8/50, Loss: 62.5519, Train Acc: 0.8297, Val Acc: 0.7620\n",
      "Epoch 9/50, Loss: 56.7361, Train Acc: 0.8437, Val Acc: 0.7625\n",
      "Epoch 10/50, Loss: 50.4117, Train Acc: 0.8604, Val Acc: 0.7649\n",
      "Epoch 11/50, Loss: 45.2039, Train Acc: 0.8724, Val Acc: 0.7661\n",
      "Epoch 12/50, Loss: 40.8167, Train Acc: 0.8850, Val Acc: 0.7625\n",
      "EarlyStopping patience: 1/7\n",
      "Epoch 13/50, Loss: 36.8348, Train Acc: 0.8953, Val Acc: 0.7670\n",
      "Epoch 14/50, Loss: 32.8762, Train Acc: 0.9067, Val Acc: 0.7675\n",
      "Epoch 15/50, Loss: 30.2474, Train Acc: 0.9130, Val Acc: 0.7711\n",
      "Epoch 16/50, Loss: 27.4601, Train Acc: 0.9211, Val Acc: 0.7717\n",
      "Epoch 17/50, Loss: 25.3410, Train Acc: 0.9266, Val Acc: 0.7680\n",
      "EarlyStopping patience: 1/7\n",
      "Epoch 18/50, Loss: 23.1995, Train Acc: 0.9327, Val Acc: 0.7698\n",
      "EarlyStopping patience: 2/7\n",
      "Epoch 19/50, Loss: 21.7059, Train Acc: 0.9360, Val Acc: 0.7686\n",
      "EarlyStopping patience: 3/7\n",
      "Epoch 20/50, Loss: 18.6258, Train Acc: 0.9455, Val Acc: 0.7736\n",
      "Epoch 21/50, Loss: 16.9362, Train Acc: 0.9513, Val Acc: 0.7741\n",
      "Epoch 22/50, Loss: 16.2278, Train Acc: 0.9531, Val Acc: 0.7679\n",
      "EarlyStopping patience: 1/7\n",
      "Epoch 23/50, Loss: 15.3257, Train Acc: 0.9561, Val Acc: 0.7710\n",
      "EarlyStopping patience: 2/7\n",
      "Epoch 24/50, Loss: 14.5495, Train Acc: 0.9577, Val Acc: 0.7711\n",
      "EarlyStopping patience: 3/7\n",
      "Epoch 25/50, Loss: 13.5945, Train Acc: 0.9606, Val Acc: 0.7719\n",
      "EarlyStopping patience: 4/7\n",
      "Epoch 26/50, Loss: 13.1645, Train Acc: 0.9624, Val Acc: 0.7725\n",
      "EarlyStopping patience: 5/7\n",
      "Epoch 27/50, Loss: 12.6684, Train Acc: 0.9640, Val Acc: 0.7731\n",
      "EarlyStopping patience: 6/7\n",
      "Epoch 28/50, Loss: 12.0021, Train Acc: 0.9659, Val Acc: 0.7724\n",
      "EarlyStopping patience: 7/7\n",
      "Early stopping triggered.\n",
      "Best model saved to ./model/bilstm_multi.pt\n",
      "Test Accuracy: 0.7579\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Step 1: Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 2: Load dataset\n",
    "df = pd.read_json(\"./data/processed/te/train.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# Step 3: Token to Index mapping\n",
    "token2idx_multi = {token: idx for idx, token in enumerate(set(token for row in df.tokens for token in row), start=1)}\n",
    "token2idx_multi[\"<PAD>\"] = 0\n",
    "\n",
    "# Step 4: Label to Index mapping\n",
    "label2idx_multi = {label: idx for idx, label in enumerate(set(label for row in df.tags for label in row), start=1)}\n",
    "label2idx_multi[\"<PAD>\"] = 0\n",
    "\n",
    "# Save the mappings\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "with open('./model/token2idx_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(token2idx_multi, f)\n",
    "with open('./model/label2idx_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(label2idx_multi, f)\n",
    "\n",
    "# Step 5: Convert tokens and labels to indices\n",
    "def encode_data(tokens, tags):\n",
    "    token_ids = [token2idx_multi[token] for token in tokens]\n",
    "    label_ids = [label2idx_multi[label] for label in tags]\n",
    "    return token_ids, label_ids\n",
    "\n",
    "df[\"encoded\"] = df.apply(lambda row: encode_data(row.tokens, row.tags), axis=1)\n",
    "\n",
    "# Step 6: Dataset class\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, df, max_len=150):\n",
    "        self.data = df\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.data.iloc[idx][\"encoded\"]\n",
    "        tokens = tokens[:self.max_len] + [0] * (self.max_len - len(tokens))\n",
    "        labels = labels[:self.max_len] + [0] * (self.max_len - len(labels))\n",
    "        return torch.tensor(tokens, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Step 7: Split into Train, Validation, Test\n",
    "dataset = NewsDataset(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Step 8: Define BiLSTM model\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=256):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.norm = nn.LayerNorm(hidden_dim * 2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = self.norm(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n",
    "\n",
    "# Step 9: Loss, Optimizer, Scheduler\n",
    "vocab_size = len(token2idx_multi)\n",
    "tagset_size = len(label2idx_multi)\n",
    "\n",
    "model = BiLSTM(vocab_size, tagset_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "# Step 10: Evaluation function\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for tokens, labels in data_loader:\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "            outputs = model(tokens)\n",
    "            predictions = torch.argmax(outputs, dim=2)\n",
    "            mask = labels != 0\n",
    "            correct += (predictions[mask] == labels[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# Step 11: Training loop with Early Stopping\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, epochs=50, patience=5):\n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for tokens, labels in train_loader:\n",
    "            tokens, labels = tokens.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens)\n",
    "            outputs = outputs.permute(0, 2, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            mask = labels != 0\n",
    "            correct += (predictions[mask] == labels[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "\n",
    "        train_accuracy = correct / total if total > 0 else 0\n",
    "        val_accuracy = evaluate_model(model, valid_loader)\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"EarlyStopping patience: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    if best_model_state:\n",
    "        os.makedirs(\"./model\", exist_ok=True)\n",
    "        torch.save(best_model_state, \"./model/bilstm_multi.pt\")\n",
    "        print(\"Best model saved to ./model/bilstm_multi.pt\")\n",
    "\n",
    "# Step 12: Train the model\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, epochs=50, patience=7)\n",
    "\n",
    "# Step 13: Final Test Accuracy\n",
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1cda977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_paragraph(model, paragraph, max_len=100):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize paragraph into words (assuming space-based for now)\n",
    "    sentences = paragraph.strip().split(\" \")  # Replace with better tokenizer if needed\n",
    "\n",
    "    # Encode each token\n",
    "    token_ids = [token2idx.get(token, 0) for token in sentences]\n",
    "    \n",
    "    # If longer than max_len, split into chunks of max_len\n",
    "    chunks = [token_ids[i:i+max_len] for i in range(0, len(token_ids), max_len)]\n",
    "    \n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for chunk in chunks:\n",
    "        actual_len = len(chunk)  # Store actual length for filtering\n",
    "        chunk = chunk + [0] * (max_len - len(chunk))  # Pad to max_len\n",
    "\n",
    "        input_tensor = torch.tensor([chunk], dtype=torch.long).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)  # Expected shape: (1, seq_len, num_classes)\n",
    "            predictions = torch.argmax(output, dim=-1).cpu().numpy()[0]\n",
    "\n",
    "        # Reverse mapping index to labels, keeping only valid tokens\n",
    "        idx2label = {v: k for k, v in label2idx.items()}\n",
    "        predicted_labels.extend([idx2label[idx] for idx in predictions[:actual_len]])\n",
    "\n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf2d40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['B-MAN_MADE_EVENT.FIRE', 'I-MAN_MADE_EVENT.FIRE', 'O', 'O', 'O', 'B-CASUALTIES-ARG', 'I-CASUALTIES-ARG', 'I-CASUALTIES-ARG', 'I-CASUALTIES-ARG']\n"
     ]
    }
   ],
   "source": [
    "example_paragraph = \"\"\"అగ్ని ప్రమాదం భవనాన్ని భస్మం చేసింది. చనిపోయిన వారి సంఖ్య పెరుగుతోంది.\"\"\"\n",
    "predicted_labels = predict_paragraph(model, example_paragraph)\n",
    "print(\"Predicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8e4099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['O', 'O', 'B-MAN_MADE_EVENT.ACCIDENTS', 'O', 'O', 'I-CASUALTIES-ARG', 'I-CASUALTIES-ARG']\n"
     ]
    }
   ],
   "source": [
    "example_paragraph = \"\"\"ఢిల్లీ లో ప్రమాదం జరిగింది మృతుల సంఖ్య పెరిగింది\"\"\"\n",
    "predicted_labels = predict_paragraph(model, example_paragraph)\n",
    "print(\"Predicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46efd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

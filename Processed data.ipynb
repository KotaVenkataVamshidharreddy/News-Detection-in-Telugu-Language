{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "CLASS_MAP = {\n",
    "    \"MAN_MADE_EVENT\": \"MANMADE_DISASTER\",\n",
    "    \"NATURAL_EVENT\": \"NATURAL_DISASTER\"\n",
    "}\n",
    "\n",
    "def transform_label(y):\n",
    "    return pd.Series(y).str.split(\".\", expand=True)[0]\n",
    "\n",
    "def transform_probs(probs, clf):\n",
    "    clf_map = defaultdict(list)\n",
    "    for c in clf.classes_:\n",
    "        clf_map[c.split(\".\")[0]].append(c)\n",
    "    df_probs = pd.DataFrame(probs, columns=clf.classes_)\n",
    "    for c_parent, children in clf_map.items():\n",
    "        df_probs[c_parent] = df_probs[children].sum(axis=1)\n",
    "    return df_probs[list(clf_map)].idxmax(axis=1)\n",
    "\n",
    "def get_w_children(node, base_node=None, split_paras=False):\n",
    "    idx = 0\n",
    "    if base_node is None:\n",
    "        base_node = ET.Element('P')\n",
    "\n",
    "    for child in node:\n",
    "        if child.tag == \"W\":\n",
    "            label = base_node.tag\n",
    "            if base_node.attrib.get(\"TYPE\"):\n",
    "                label = f\"{label}.{base_node.attrib['TYPE']}\"\n",
    "            label = f\"B-{label}\" if idx == 0 else f\"I-{label}\"\n",
    "            if base_node.tag == \"P\":\n",
    "                label = \"O\"\n",
    "            token_text = (child.text or \"\").strip()\n",
    "            if token_text:\n",
    "                yield token_text, label\n",
    "                idx += 1\n",
    "        else:\n",
    "            yield from get_w_children(child, base_node=child)\n",
    "    if split_paras and node.tag == \"P\":\n",
    "        yield \"<P>\", \"P\"\n",
    "\n",
    "def get_w_children_test(node, base_node=None, split_paras=False):\n",
    "    for child in node:\n",
    "        if child.tag == \"P\":\n",
    "            text_content = child.text or \"\"\n",
    "            tokens = [t.strip() for t in text_content.split(\"  \") if t.strip()]\n",
    "            for token in tokens:\n",
    "                yield token, \"O\"\n",
    "            if split_paras:\n",
    "                yield \"<P>\", \"P\"\n",
    "\n",
    "def split_tag(tag):\n",
    "    return tuple(tag.split(\"-\", 1)) if tag != \"O\" else (tag, None)\n",
    "\n",
    "def extract_entities(tags):\n",
    "    tags = list(tags)\n",
    "    curr_entity = []\n",
    "    entities = []\n",
    "    for i, tag in enumerate(tags + [\"O\"]):\n",
    "        boundary, label = split_tag(tag)\n",
    "        if curr_entity:\n",
    "            if boundary in {\"B\", \"O\"} or label != curr_entity[-1][1]:\n",
    "                start = i - len(curr_entity)\n",
    "                end = i\n",
    "                entity_label = curr_entity[-1][1]\n",
    "                entities.append((entity_label, start, end))\n",
    "                curr_entity = []\n",
    "            elif boundary == \"I\":\n",
    "                curr_entity.append((boundary, label))\n",
    "        if boundary == \"B\":\n",
    "            assert not curr_entity, f\"Entity should be empty. Found: {curr_entity}\"\n",
    "            curr_entity.append((boundary, label))\n",
    "    return entities\n",
    "\n",
    "def get_entity_info(bio_labels, tokens, text=None, spans=None):\n",
    "    entities_info = extract_entities(bio_labels)\n",
    "    entities = []\n",
    "    for label, start, end in entities_info:\n",
    "        entity_phrase = \" \".join(tokens[start:end])\n",
    "        entities.append(dict(\n",
    "            tokens=tokens[start:end],\n",
    "            label=label,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            entity_phrase=entity_phrase\n",
    "        ))\n",
    "    return entities\n",
    "\n",
    "def xml_to_conll(xml_path, test=False):\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        parse_fn = get_w_children_test if test else get_w_children\n",
    "        seq = list(parse_fn(root))\n",
    "        return seq\n",
    "    except Exception as e:\n",
    "        print(f\" Error parsing XML file {xml_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def xml_to_json(xml_path, test=False):\n",
    "    seq = xml_to_conll(xml_path, test=test)\n",
    "    if not seq:\n",
    "        print(f\" Skipping file {xml_path} due to errors\")\n",
    "        return {\"docid\": xml_path.stem, \"tokens\": [], \"tags\": [], \"labels\": {}}\n",
    "\n",
    "    docid = xml_path.stem\n",
    "    tokens, tags = zip(*seq) if seq else ([], [])\n",
    "\n",
    "    labels = Counter([t[2:] for t in tags if t.startswith((\"B-MAN_MADE_EVENT\", \"B-NATURAL_EVENT\"))])\n",
    "    return {\n",
    "        \"docid\": docid,\n",
    "        \"tokens\": tokens,\n",
    "        \"tags\": tags,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "import json\n",
    "\n",
    "def process(xml_dir_path, test=False):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "\n",
    "    xml_dir = Path(xml_dir_path)\n",
    "\n",
    "    # Exact file name and path\n",
    "    output_path = Path(r\"C:\\semisters\\SEM6\\NLP\\F_project\\data\\processed\\te\\train.json\")\n",
    "\n",
    "    files = list(xml_dir.glob(\"*.xml\"))\n",
    "    if not files:\n",
    "        print(f\" No XML files found in {xml_dir}\")\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "    for xml_file in files:\n",
    "        json_data = xml_to_json(xml_file, test=test)\n",
    "        all_data.append(json_data)\n",
    "\n",
    "    # Make sure the target directory exists\n",
    "    os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "    # Write to train.json\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in all_data:\n",
    "            f.write(json.dumps(entry, ensure_ascii=True) + \"\\n\")\n",
    "\n",
    "    print(f\" Successfully saved output to {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(r'C:\\semisters\\SEM6\\NLP\\F_project\\data\\raw\\te\\Train\\file01.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'DOCUMENT' at 0x000001EEBFB6DEF0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('జమ్మూవిల్లే', 'B-PLACE-ARG'),\n",
       " ('భారీ వర్షపాతం ద్వారా', 'B-REASON-ARG'),\n",
       " ('చాలా', 'O'),\n",
       " ('స్థానాలు', 'O'),\n",
       " ('కొండచరియలు', 'B-NATURAL_EVENT.LAND_SLIDE'),\n",
       " ('రవాణా', 'B-AFTER_EFFECTS-ARG'),\n",
       " ('కత్తిరించండి', 'I-AFTER_EFFECTS-ARG'),\n",
       " ('జమ్మూ', 'O'),\n",
       " ('జమ్మూ', 'O'),\n",
       " ('కాశ్మీర్', 'O'),\n",
       " ('రాష్ట్రంలో', 'O'),\n",
       " ('రోజులు', 'B-TIME-ARG'),\n",
       " ('భారీ వర్షం', 'O'),\n",
       " ('నియామకం', 'O'),\n",
       " ('పైకి వస్తుంది', 'O'),\n",
       " ('ప్రత్యేకంగా', 'O'),\n",
       " ('రాంబన్', 'B-PLACE-ARG'),\n",
       " ('ఉదంబూర్', 'I-PLACE-ARG'),\n",
       " ('జిల్లాల్లో', 'I-PLACE-ARG'),\n",
       " ('ఉధెం', 'B-REASON-ARG'),\n",
       " ('షవర్', 'I-REASON-ARG'),\n",
       " ('బ్లీచింగ్', 'I-REASON-ARG'),\n",
       " ('కొనుగోలు', 'I-REASON-ARG'),\n",
       " ('జిల్లాలు', 'O'),\n",
       " ('చాలా', 'O'),\n",
       " ('స్థానాలు', 'O'),\n",
       " ('కొండచరియలు', 'B-NATURAL_EVENT.LAND_SLIDE'),\n",
       " ('సంభవించింది', 'O'),\n",
       " ('కొండచరియలు ఉంటే', 'B-NATURAL_EVENT.LAND_SLIDE'),\n",
       " ('చాలా', 'O'),\n",
       " ('స్థానాలు', 'O'),\n",
       " ('రవాణా', 'B-AFTER_EFFECTS-ARG'),\n",
       " ('కత్తిరించబడింది', 'I-AFTER_EFFECTS-ARG'),\n",
       " ('గురించి', 'O'),\n",
       " ('రవాణా', 'O'),\n",
       " ('అధికారం', 'O'),\n",
       " ('ఒకటి', 'O'),\n",
       " ('అది చెప్పినప్పుడు', 'O'),\n",
       " ('ఉదంబూర్', 'B-PLACE-ARG'),\n",
       " ('జిల్లా', 'I-PLACE-ARG'),\n",
       " ('జాతీయ', 'I-PLACE-ARG'),\n",
       " ('హై వే', 'I-PLACE-ARG'),\n",
       " ('కొండచరియలు ఉంటే', 'B-NATURAL_EVENT.LAND_SLIDE'),\n",
       " ('మూసివేయబడింది', 'O'),\n",
       " ('అనుసరించండి', 'O'),\n",
       " ('భారీ వర్షం', 'O'),\n",
       " ('నియామకం', 'O'),\n",
       " ('అది వచ్చినట్లు', 'O'),\n",
       " ('రోడ్', 'O'),\n",
       " ('కుడి', 'O'),\n",
       " ('విల్', 'O'),\n",
       " ('పని', 'O'),\n",
       " ('స్తంభించిపోయింది', 'O'),\n",
       " ('షవర్', 'O'),\n",
       " ('ఓడా', 'O'),\n",
       " ('తరువాత మాత్రమే', 'O'),\n",
       " ('కొండచరియలు ఉంటే', 'B-NATURAL_EVENT.LAND_SLIDE'),\n",
       " ('విడదీయండి', 'O'),\n",
       " ('రోడ్లు', 'O'),\n",
       " ('కుడి', 'O'),\n",
       " ('చేయడానికి', 'O'),\n",
       " ('సాధ్యమే', 'O'),\n",
       " ('అన్నారు', 'O'),\n",
       " ('ఈలోగా', 'O'),\n",
       " ('నిన్న మరియు', 'O'),\n",
       " ('బ్లీచింగ్', 'O'),\n",
       " ('సంపాదించబడింది', 'O'),\n",
       " ('ఉధెం', 'O'),\n",
       " ('వర్షం ద్వారా', 'O'),\n",
       " ('సుమారు', 'O'),\n",
       " ('పూస', 'O'),\n",
       " ('సమయం', 'O'),\n",
       " ('జాతీయ', 'O'),\n",
       " ('హై వే', 'O'),\n",
       " ('కవర్ చేయబడింది', 'O'),\n",
       " ('విశేషంగా', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_w_children(root))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docid': 'file501', 'tokens': ('వరదలు', 'సెర్బియా', 'మోడీ', 'ప్రభుత్వం', 'సహాయకారి', 'నిరీక్షణ', 'ఏదైనా', 'రోజు నుండి రోజుకు', 'వరదలు కారణంగా', 'వదిలివేసిన వారిలో', 'నష్టం', 'కారణం', 'సెర్బియా', 'దేశం', 'తిరిగి మూల్యాంకనం కోసం', 'భారతదేశం', 'కొత్తగా', 'స్థాపన', 'కారణం', 'మోడీ', 'ప్రభుత్వం', 'సహాయకారి', 'నిరీక్షణ', 'కెల్లీ', 'సెర్బియా', 'భారతదేశంలో', 'రాయబారి', 'డాన్', 'మిరిలోవిక్', 'సమాచారం', 'ఇవ్వబడింది', 'మిరిలోవిమ్', 'అన్నారు', 'సెర్బియా', 'మూడు', 'నెల', 'పతనం', 'కారిడార్', 'వర్షం', 'మూడు', 'రోజు', 'పడిపోతుంది', 'ఈ కారణంగా', 'దేశాలు', 'వదిలివేసిన వారిలో', 'నష్టం', 'జరిగింది', 'మే', 'మే', 'వరకు', 'దేశంలో', 'అత్యవసర పరిస్థితి', 'పబ్లిక్', 'వచ్చింది', 'కారిడార్', 'వర్షాలు', 'దేశం ముందు', 'గొప్పది', 'సంక్షోభం', 'సృష్టి', 'తయారు చేయబడింది', 'ఏమైనా', 'దేశం', 'అనేక', 'పాక్షిక', 'ఎక్స్ట్రీమ్', 'నష్టం', 'జరిగింది', 'దెబ్బతింది', 'పాక్షిక', 'వినోదం', 'చేయడానికి', 'అవసరం', 'తయారు చేయబడింది', 'దాని కోసం', 'మాకు', 'మోడీ', 'ప్రభుత్వం', 'సహాయకారి', 'నిరీక్షణ', 'భారతీయుడు', 'సహాయం ద్వారా', 'మేము', 'ఇబ్బందుల్లో', 'అవుట్', 'అనుసరించండి', 'కెన్', 'ఆ విధంగా', 'మాకు', 'విశ్వాసం', 'అనుభూతి', 'సెర్బియా', 'అనేక', 'ఈ రోజు కూడా', 'వర్షం', 'నీరు', 'నిండి ఉంది', 'ఏమైనా', 'రోడ్లు భవనాలు', 'ఆస్తులు', 'పెద్దది', 'నష్టం', 'జరిగింది'), 'tags': ('B-NATURAL_EVENT.FLOODS', 'B-PLACE-ARG', 'O', 'O', 'O', 'O', 'B-TIME-ARG', 'I-TIME-ARG', 'B-NATURAL_EVENT.FLOODS', 'B-AFTER_EFFECTS-ARG', 'I-AFTER_EFFECTS-ARG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'), 'labels': Counter({'NATURAL_EVENT.FLOODS': 2})}\n"
     ]
    }
   ],
   "source": [
    "xml_path = Path(r'C:\\semisters\\SEM6\\NLP\\F_project\\data\\raw\\te\\Train\\file501.xml')\n",
    "json_data = xml_to_json(xml_path)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': ('వరదలు',),\n",
       "  'label': 'NATURAL_EVENT.FLOODS',\n",
       "  'start': 0,\n",
       "  'end': 1,\n",
       "  'entity_phrase': 'వరదలు'},\n",
       " {'tokens': ('సెర్బియా',),\n",
       "  'label': 'PLACE-ARG',\n",
       "  'start': 1,\n",
       "  'end': 2,\n",
       "  'entity_phrase': 'సెర్బియా'},\n",
       " {'tokens': ('ఏదైనా', 'రోజు నుండి రోజుకు'),\n",
       "  'label': 'TIME-ARG',\n",
       "  'start': 6,\n",
       "  'end': 8,\n",
       "  'entity_phrase': 'ఏదైనా రోజు నుండి రోజుకు'},\n",
       " {'tokens': ('వరదలు కారణంగా',),\n",
       "  'label': 'NATURAL_EVENT.FLOODS',\n",
       "  'start': 8,\n",
       "  'end': 9,\n",
       "  'entity_phrase': 'వరదలు కారణంగా'},\n",
       " {'tokens': ('వదిలివేసిన వారిలో', 'నష్టం'),\n",
       "  'label': 'AFTER_EFFECTS-ARG',\n",
       "  'start': 9,\n",
       "  'end': 11,\n",
       "  'entity_phrase': 'వదిలివేసిన వారిలో నష్టం'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_info(json_data[\"tags\"], json_data[\"tokens\"], text=None, spans=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully saved output to C:\\semisters\\SEM6\\NLP\\F_project\\data\\processed\\te\\train.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process(r\"C:\\Users\\kotav\\Desktop\\NLP\\data\\raw\\te\\Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
